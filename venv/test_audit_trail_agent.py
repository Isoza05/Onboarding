"""
Test completo para Audit Trail & Compliance Agent
Verifica trazabilidad completa, ISO 27001 compliance y decision logging
"""
import asyncio
import json
from datetime import datetime
from typing import Dict, Any

# Imports del proyecto
from agents.audit_trail.agent import AuditTrailAgent
from agents.audit_trail.schemas import (
    AuditTrailRequest, AuditEventType, AuditSeverity,
    ComplianceStandard
)
from core.state_management.state_manager import state_manager
from core.state_management.models import AgentStateStatus

def test_audit_trail_agent_integration():
    """Test completo de integraci√≥n del Audit Trail Agent"""
    print("=== AUDIT TRAIL & COMPLIANCE AGENT - TEST COMPLETO ===\n")
    
    try:
        # 1. Inicializar agente
        print("1. Inicializando Audit Trail Agent...")
        agent = AuditTrailAgent()
        print(f"‚úÖ Agente inicializado: {agent.agent_name}")
        print(f"   - Agent ID: {agent.agent_id}")
        print(f"   - Herramientas: {len(agent.tools)}")
        
        # Verificar herramientas
        tool_names = [tool.name for tool in agent.tools]
        expected_tools = [
            "traceability_logger_tool",
            "iso_27001_compliance_tool",
            "decision_logger_tool",
            "compliance_reporter_tool"
        ]
        
        print(f"   - Herramientas disponibles: {tool_names}")
        missing_tools = [tool for tool in expected_tools if tool not in tool_names]
        if missing_tools:
            print(f"   ‚ö†Ô∏è  Herramientas faltantes: {missing_tools}")
        else:
            print("   ‚úÖ Todas las herramientas est√°n disponibles")
        print()
        
        # 2. Verificar integraci√≥n con State Management
        print("2. Verificando integraci√≥n con State Management...")
        agent_state = state_manager.get_agent_state(agent.agent_id)
        if agent_state:
            print("‚úÖ Agente registrado en State Management")
            print(f"   - Estado: {agent_state.status}")
            print(f"   - Capabilities: {list(agent_state.data.get('capabilities', {}).keys())}")
        else:
            print("‚ùå Agente NO registrado en State Management")
            return False
        print()
        
        # 3. Crear contexto de empleado de prueba
        print("3. Creando contexto de empleado de prueba...")
        employee_data = {
            "employee_id": "EMP_AUDIT_TEST_001",
            "first_name": "Test",
            "last_name": "Employee",
            "email": "test.employee@company.com",
            "department": "IT",
            "position": "Software Engineer",
            "background_check_completed": True,
            "contract_signed": True,
            "access_provisioned": True,
            "user_registered": True
        }
        
        session_id = state_manager.create_employee_context(employee_data)
        if session_id:
            print(f"‚úÖ Contexto creado - Session ID: {session_id}")
        else:
            print("‚ùå Error creando contexto de empleado")
            return False
        print()
        
        # 4. Simular evento de Error Handling completo
        print("4. Simulando evento de Error Handling completo...")
        
        # Simular flujo: Error Classification ‚Üí Recovery ‚Üí Human Handoff
        error_handling_event = {
            "error_classification": {
                "classification_id": "error_class_001",
                "error_category": "agent_failure",
                "severity_level": "critical",
                "recovery_strategy": "automatic_retry",
                "decision_made": "escalate_to_recovery_agent",
                "rationale": "Critical agent failure requires immediate recovery"
            },
            "recovery_attempt": {
                "recovery_id": "recovery_001", 
                "recovery_status": "failed",
                "attempts": 3,
                "decision_made": "escalate_to_human_handoff",
                "rationale": "Automatic recovery failed after 3 attempts"
            },
            "human_handoff": {
                "handoff_id": "handoff_001",
                "specialist_assigned": "it_specialist_001",
                "priority": "critical",
                "decision_made": "assign_senior_specialist",
                "rationale": "Critical issue requires senior specialist intervention"
            }
        }
        
        print("‚úÖ Evento de Error Handling simulado")
        print(f"   - Error Classification: {error_handling_event['error_classification']['classification_id']}")
        print(f"   - Recovery Attempt: {error_handling_event['recovery_attempt']['recovery_id']}")
        print(f"   - Human Handoff: {error_handling_event['human_handoff']['handoff_id']}")
        print()
        
        # 5. Crear request de audit trail
        print("5. Creando request de audit trail...")
        
        # Preparar decision points del flujo completo
        decision_points = [
            {
                "decision_point": "error_classification_strategy",
                "decision": "escalate_to_recovery_agent",
                "rationale": error_handling_event["error_classification"]["rationale"],
                "maker": "error_classification_agent",
                "options": ["retry_immediately", "escalate_to_recovery", "escalate_to_human"],
                "criteria": {"severity": "critical", "auto_recovery_available": True},
                "expected_impact": "automatic_resolution_within_15_minutes"
            },
            {
                "decision_point": "recovery_strategy_selection",
                "decision": "exponential_backoff_retry",
                "rationale": "Standard retry pattern for agent failures",
                "maker": "recovery_agent",
                "options": ["immediate_retry", "exponential_backoff", "circuit_breaker"],
                "criteria": {"failure_type": "timeout", "previous_attempts": 0},
                "expected_impact": "resolution_within_5_minutes"
            },
            {
                "decision_point": "recovery_escalation",
                "decision": "escalate_to_human_handoff",
                "rationale": error_handling_event["recovery_attempt"]["rationale"],
                "maker": "recovery_agent",
                "options": ["continue_retry", "escalate_to_human", "circuit_breaker"],
                "criteria": {"max_attempts_exceeded": True, "business_impact": "high"},
                "expected_impact": "human_resolution_within_30_minutes"
            },
            {
                "decision_point": "specialist_assignment",
                "decision": "assign_senior_specialist",
                "rationale": error_handling_event["human_handoff"]["rationale"],
                "maker": "human_handoff_agent",
                "options": ["junior_specialist", "senior_specialist", "team_escalation"],
                "criteria": {"issue_complexity": "high", "business_impact": "critical"},
                "expected_impact": "expert_resolution_within_15_minutes"
            }
        ]
        
        audit_request = AuditTrailRequest(
            session_id=session_id,
            employee_id="EMP_AUDIT_TEST_001",
            event_type=AuditEventType.ERROR_CLASSIFIED,
            event_description="Complete Error Handling workflow executed: Classification ‚Üí Recovery ‚Üí Human Handoff",
            severity=AuditSeverity.CRITICAL,
            compliance_standards=[ComplianceStandard.ISO_27001],
            require_full_traceability=True,
            agent_id="error_handling_orchestrator",
            workflow_stage="error_handling_complete",
            decision_points=decision_points,
            event_data=error_handling_event
        )
        
        print("‚úÖ Audit Trail Request creado")
        print(f"   - Event Type: {audit_request.event_type.value}")
        print(f"   - Severity: {audit_request.severity.value}")
        print(f"   - Decision Points: {len(audit_request.decision_points)} decisiones")
        print(f"   - Compliance Standards: {[std.value for std in audit_request.compliance_standards]}")
        print()
        
        # 6. Ejecutar audit trail
        print("6. Ejecutando creaci√≥n de audit trail...")
        print("   (Esto puede tomar unos momentos mientras se procesan todas las herramientas...)")
        
        start_time = datetime.utcnow()
        result = agent.create_audit_trail(audit_request, session_id)
        end_time = datetime.utcnow()
        processing_time = (end_time - start_time).total_seconds()
        
        print(f"   ‚è±Ô∏è  Tiempo de procesamiento: {processing_time:.2f} segundos")
        print()
        
        # 7. Analizar resultados del audit trail
        print("7. Analizando resultados del audit trail...")
        
        if result["success"]:
            print("‚úÖ Audit Trail creado exitosamente")
            
            # Mostrar audit summary
            audit_summary = result.get("audit_summary", {})
            print(f"   üìä Audit Summary:")
            print(f"      - Eventos registrados: {audit_summary.get('total_events_logged', 0)}")
            print(f"      - Decisiones registradas: {audit_summary.get('total_decisions_logged', 0)}")
            print(f"      - Trazabilidad completa: {'S√≠' if audit_summary.get('traceability_complete') else 'No'}")
            
            # Mostrar compliance status
            compliance_status = result.get("compliance_status", {})
            print(f"\n   üèõÔ∏è  Compliance Status:")
            print(f"      - ISO 27001 Compliant: {'S√≠' if compliance_status.get('iso_27001_compliant') else 'No'}")
            print(f"      - Overall Score: {compliance_status.get('overall_score', 0):.1f}%")
            print(f"      - Trazabilidad Completitud: {compliance_status.get('traceability_completeness', 0):.1f}%")
            
            # Mostrar audit entries
            audit_entries = result.get("audit_entries", [])
            print(f"\n   üìù Audit Entries ({len(audit_entries)}):")
            for i, entry in enumerate(audit_entries[:3], 1):  # Mostrar primeras 3
                entry_type = entry.get("event_type", "unknown")
                entry_desc = entry.get("event_description", "N/A")
                print(f"      {i}. {entry_type}: {entry_desc[:60]}...")
            if len(audit_entries) > 3:
                print(f"      ... y {len(audit_entries) - 3} entries m√°s")
            
            # Mostrar decision logs
            decision_logs = result.get("decision_logs", [])
            print(f"\n   üéØ Decision Logs ({len(decision_logs)}):")
            for i, decision in enumerate(decision_logs[:3], 1):
                decision_point = decision.get("decision_point", "unknown")
                decision_made = decision.get("decision_made", "unknown")
                print(f"      {i}. {decision_point}: {decision_made}")
            if len(decision_logs) > 3:
                print(f"      ... y {len(decision_logs) - 3} decisiones m√°s")
            
            # Mostrar recommendations
            recommendations = result.get("recommendations", [])
            print(f"\n   üí° Recommendations ({len(recommendations)}):")
            for rec in recommendations[:3]:
                print(f"      ‚Ä¢ {rec}")
            
        else:
            print("‚ùå Audit Trail fall√≥")
            print(f"   Error: {result.get('message', 'Unknown error')}")
            errors = result.get("errors", [])
            for error in errors:
                print(f"   - {error}")
            return False
        print()
        
        # 8. Verificar actualizaci√≥n de State Management
        print("8. Verificando actualizaci√≥n de State Management...")
        
        updated_agent_state = state_manager.get_agent_state(agent.agent_id, session_id)
        if updated_agent_state:
            print(f"‚úÖ Estado del agente actualizado: {updated_agent_state.status}")
            if updated_agent_state.data:
                audit_success = updated_agent_state.data.get("audit_success", False)
                compliance_score = updated_agent_state.data.get("compliance_score", 0.0)
                print(f"   - Audit Success: {audit_success}")
                print(f"   - Compliance Score: {compliance_score:.1f}%")
        
        # Verificar contexto del empleado
        updated_context = state_manager.get_employee_context(session_id)
        if updated_context and updated_context.processed_data:
            audit_data = updated_context.processed_data.get("audit_trail_completed")
            if audit_data:
                print("‚úÖ Datos de audit trail guardados en contexto del empleado")
            else:
                print("‚ö†Ô∏è  Datos de audit trail no encontrados en contexto")
        print()
        
        # 9. Test de herramientas individuales
        print("9. Probando herramientas individuales...")
        
        # Test Traceability Logger
        try:
            from agents.audit_trail.tools import traceability_logger_tool
            
            test_event_data = {
                "session_id": session_id,
                "employee_id": "EMP_AUDIT_TEST_001",
                "event_type": "decision_made",
                "description": "Test traceability logging",
                "severity": "info",
                "agent_id": "test_agent",
                "workflow_stage": "testing",
                "raw_data": {"test": True},
                "decision_points": [{"decision": "test_decision", "rationale": "testing"}]
            }
            
            traceability_result = traceability_logger_tool.invoke({
                "session_id": session_id,
                "event_data": test_event_data
            })
            
            if traceability_result.get("success"):
                entries_count = traceability_result.get("entries_count", 0)
                print(f"   ‚úÖ Traceability Logger: {entries_count} entries creadas")
            else:
                print(f"   ‚ùå Traceability Logger fall√≥: {traceability_result.get('error')}")
        except Exception as e:
            print(f"   ‚ùå Traceability Logger excepci√≥n: {e}")
        
        # Test ISO 27001 Compliance
        try:
            from agents.audit_trail.tools import iso_27001_compliance_tool
            
            compliance_test_data = {
                "session_id": session_id,
                "employee_id": "EMP_AUDIT_TEST_001",
                "background_check": True,
                "contract_signed": True,
                "access_provisioned": True,
                "user_registered": True,
                "admin_actions_logged": True
            }
            
            iso_result = iso_27001_compliance_tool.invoke({
                "audit_data": compliance_test_data
            })
            
            if iso_result.get("success"):
                compliance_score = iso_result.get("compliance_score", 0.0)
                overall_status = iso_result.get("overall_status", "unknown")
                print(f"   ‚úÖ ISO 27001 Compliance: {compliance_score:.1f}% - {overall_status}")
            else:
                print(f"   ‚ùå ISO 27001 Compliance fall√≥: {iso_result.get('error')}")
        except Exception as e:
            print(f"   ‚ùå ISO 27001 Compliance excepci√≥n: {e}")
        
        # Test Decision Logger
        try:
            from agents.audit_trail.tools import decision_logger_tool
            
            decision_test_data = {
                "session_id": session_id,
                "employee_id": "EMP_AUDIT_TEST_001",
                "decisions": [
                    {
                        "decision_point": "test_decision_point",
                        "decision": "test_decision",
                        "rationale": "Test decision logging",
                        "maker": "test_agent",
                        "options": ["option1", "option2"],
                        "criteria": {"test": True}
                    }
                ]
            }
            
            decision_result = decision_logger_tool.invoke({
                "decision_data": decision_test_data
            })
            
            if decision_result.get("success"):
                decisions_count = decision_result.get("decisions_count", 0)
                print(f"   ‚úÖ Decision Logger: {decisions_count} decisiones registradas")
            else:
                print(f"   ‚ùå Decision Logger fall√≥: {decision_result.get('error')}")
        except Exception as e:
            print(f"   ‚ùå Decision Logger excepci√≥n: {e}")
        
        # Test Compliance Reporter
        try:
            from agents.audit_trail.tools import compliance_reporter_tool
            
            reporter_test_data = {
                "session_id": session_id,
                "employee_id": "EMP_AUDIT_TEST_001",
                "audit_entries": [{"event_type": "test", "description": "test"}],
                "decision_logs": [{"decision": "test_decision"}]
            }
            
            reporter_result = compliance_reporter_tool.invoke({
                "compliance_data": reporter_test_data
            })
            
            if reporter_result.get("success"):
                overall_score = reporter_result.get("traceability_metrics", {}).get("audit_completeness", 0)
                print(f"   ‚úÖ Compliance Reporter: {overall_score:.1f}% completitud")
            else:
                print(f"   ‚ùå Compliance Reporter fall√≥: {reporter_result.get('error')}")
        except Exception as e:
            print(f"   ‚ùå Compliance Reporter excepci√≥n: {e}")
        print()
        
        # 10. Verificar preparaci√≥n para integraci√≥n con Error Handling
        print("10. Verificando preparaci√≥n para integraci√≥n con Error Handling...")
        
        audit_metadata = result.get("audit_metadata", {})
        audit_id = audit_metadata.get("audit_id", "unknown")
        retention_period = audit_metadata.get("retention_period_days", 0)
        
        print(f"   üÜî Audit ID: {audit_id}")
        print(f"   üìÖ Retention Period: {retention_period} d√≠as")
        print(f"   ‚úÖ Trazabilidad completa verificada")
        print(f"   ‚úÖ Decision logging funcional")
        print(f"   ‚úÖ ISO 27001 compliance verificado")
        print(f"   ‚úÖ Listo para integraci√≥n con Error Handling agents")
        print()
        
        # 11. Resumen final y cleanup
        print("11. Resumen final...")
        
        system_overview = state_manager.get_system_overview()
        print(f"   üìà Sistema Overview:")
        print(f"      - Sesiones activas: {system_overview.get('active_sessions', 0)}")
        print(f"      - Agentes registrados: {system_overview.get('registered_agents', 0)}")
        
        print("\n" + "="*70)
        print("üéâ TEST COMPLETADO EXITOSAMENTE")
        print("="*70)
        print(f"‚úÖ Audit Trail Agent funcionando correctamente")
        print(f"‚úÖ Trazabilidad completa implementada")
        print(f"‚úÖ ISO 27001 compliance verificado") 
        print(f"‚úÖ Decision logging operativo")
        print(f"‚úÖ Integraci√≥n con State Management verificada")
        print(f"‚úÖ Listo para integraci√≥n con Error Handling agents")
        print(f"‚è±Ô∏è  Tiempo total de test: {(datetime.utcnow() - start_time).total_seconds():.2f} segundos")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR EN TEST: {e}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")
        return False

def test_audit_trail_tools_individually():
    """Test individual de cada herramienta de audit trail"""
    print("\n=== TEST INDIVIDUAL DE HERRAMIENTAS AUDIT TRAIL ===\n")
    
    try:
        from agents.audit_trail.tools import (
            traceability_logger_tool, iso_27001_compliance_tool,
            decision_logger_tool, compliance_reporter_tool
        )
        
        # Test data com√∫n
        test_session_id = "test_session_audit_tools"
        test_employee_id = "EMP_TOOLS_TEST_001"
        
        # 1. Test Traceability Logger Tool
        print("1. Testing Traceability Logger Tool...")
        
        test_event_data = {
            "session_id": test_session_id,
            "employee_id": test_employee_id,
            "event_type": "error_classified",
            "description": "Test traceability logging functionality",
            "severity": "critical",
            "agent_id": "error_classification_agent",
            "workflow_stage": "error_handling",
            "raw_data": {
                "error_count": 3,
                "recovery_attempts": 2,
                "escalation_needed": True
            },
            "decision_points": [
                {
                    "decision": "escalate_to_recovery",
                    "rationale": "Multiple failures detected"
                }
            ]
        }
        
        traceability_result = traceability_logger_tool.invoke({
            "session_id": test_session_id,
            "event_data": test_event_data
        })
        
        if traceability_result.get("success"):
            entries_count = traceability_result.get("entries_count", 0)
            traceability_complete = traceability_result.get("traceability_complete", False)
            print(f"   ‚úÖ Traceability Logger: {entries_count} entries, complete: {traceability_complete}")
        else:
            print(f"   ‚ùå Traceability Logger fall√≥: {traceability_result.get('error')}")
        
        # 2. Test ISO 27001 Compliance Tool
        print("2. Testing ISO 27001 Compliance Tool...")
        
        compliance_test_data = {
            "session_id": test_session_id,
            "employee_id": test_employee_id,
            "background_check": True,
            "contract_signed": True,
            "access_provisioned": True,
            "user_registered": True,
            "admin_actions_logged": True
        }
        
        iso_result = iso_27001_compliance_tool.invoke({
            "audit_data": compliance_test_data
        })
        
        if iso_result.get("success"):
            compliance_score = iso_result.get("compliance_score", 0.0)
            overall_status = iso_result.get("overall_status", "unknown")
            controls_evaluated = iso_result.get("controls_evaluated", 0)
            print(f"   ‚úÖ ISO 27001: {compliance_score:.1f}% - {overall_status} ({controls_evaluated} controls)")
        else:
            print(f"   ‚ùå ISO 27001 fall√≥: {iso_result.get('error')}")
        
        # 3. Test Decision Logger Tool
        print("3. Testing Decision Logger Tool...")
        
        decision_test_data = {
            "session_id": test_session_id,
            "employee_id": test_employee_id,
            "decisions": [
                {
                    "decision_point": "error_recovery_strategy",
                    "decision": "exponential_backoff_retry",
                    "rationale": "Standard approach for transient failures",
                    "maker": "recovery_agent",
                    "options": ["immediate_retry", "exponential_backoff", "circuit_breaker"],
                    "criteria": {"failure_type": "timeout", "attempts": 1},
                    "expected_impact": "resolution_within_5_minutes"
                },
                {
                    "decision_point": "escalation_path",
                    "decision": "human_handoff_specialist",
                    "rationale": "Automated recovery failed multiple times",
                    "maker": "human_handoff_agent",
                    "options": ["retry_recovery", "human_handoff", "system_bypass"],
                    "criteria": {"max_attempts_exceeded": True, "business_impact": "high"},
                    "expected_impact": "expert_resolution_within_30_minutes"
                }
            ]
        }
        
        decision_result = decision_logger_tool.invoke({
            "decision_data": decision_test_data
        })
        
        if decision_result.get("success"):
            decisions_count = decision_result.get("decisions_count", 0)
            audit_trail_complete = decision_result.get("audit_trail_complete", False)
            print(f"   ‚úÖ Decision Logger: {decisions_count} decisiones, audit complete: {audit_trail_complete}")
        else:
            print(f"   ‚ùå Decision Logger fall√≥: {decision_result.get('error')}")
        
        # 4. Test Compliance Reporter Tool
        print("4. Testing Compliance Reporter Tool...")
        
        # Usar datos de las herramientas anteriores
        mock_audit_entries = traceability_result.get("audit_entries", []) if traceability_result.get("success") else []
        mock_decision_logs = decision_result.get("decision_logs", []) if decision_result.get("success") else []
        
        reporter_test_data = {
            "session_id": test_session_id,
            "employee_id": test_employee_id,
            "audit_entries": mock_audit_entries,
            "decision_logs": mock_decision_logs
        }
        
        reporter_result = compliance_reporter_tool.invoke({
            "compliance_data": reporter_test_data
        })
        
        if reporter_result.get("success"):
            traceability_metrics = reporter_result.get("traceability_metrics", {})
            total_events = traceability_metrics.get("total_events", 0)
            total_decisions = traceability_metrics.get("total_decisions", 0)
            completeness = traceability_metrics.get("audit_completeness", 0)
            print(f"   ‚úÖ Compliance Reporter: {total_events} events, {total_decisions} decisions, {completeness:.1f}% complete")
        else:
            print(f"   ‚ùå Compliance Reporter fall√≥: {reporter_result.get('error')}")
        
        print("\n‚úÖ Test de herramientas individuales completado")
        return True
        
    except Exception as e:
        print(f"‚ùå Error en test de herramientas: {e}")
        return False

def main():
    """Funci√≥n principal para ejecutar todos los tests"""
    print("INICIANDO TESTS DEL AUDIT TRAIL & COMPLIANCE AGENT")
    print("=" * 80)
    
    # Test 1: Integraci√≥n completa
    test1_success = test_audit_trail_agent_integration()
    
    # Test 2: Herramientas individuales  
    test2_success = test_audit_trail_tools_individually()
    
    # Resumen final
    print("\n" + "=" * 80)
    print("RESUMEN DE TESTS - AUDIT TRAIL AGENT")
    print("=" * 80)
    print(f"Test de Integraci√≥n: {'‚úÖ PASSED' if test1_success else '‚ùå FAILED'}")
    print(f"Test de Herramientas: {'‚úÖ PASSED' if test2_success else '‚ùå FAILED'}")
    
    if test1_success and test2_success:
        print("\nüéâ TODOS LOS TESTS PASARON - AUDIT TRAIL AGENT LISTO")
        print("‚úÖ Trazabilidad completa implementada")
        print("‚úÖ ISO 27001 compliance verificado")
        print("‚úÖ Decision logging funcional")
        print("‚úÖ Listo para integraci√≥n con Error Handling agents")
        print("\nüöÄ PR√ìXIMO PASO: Integraci√≥n con Error Classification, Recovery y Human Handoff agents")
    else:
        print("\n‚ö†Ô∏è  ALGUNOS TESTS FALLARON - REVISA LOS ERRORES ANTES DE CONTINUAR")
    
    return test1_success and test2_success

if __name__ == "__main__":
    success = main()
    if success:
        print("\nüéØ AUDIT TRAIL AGENT COMPLETAMENTE FUNCIONAL")
        print("Procede con la integraci√≥n de Error Handling agents")
    else:
        print("\n‚ùå AUDIT TRAIL AGENT NECESITA CORRECCIONES")