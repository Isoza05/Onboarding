import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from agents.progress_tracker.agent import ProgressTrackerAgent
from agents.progress_tracker.schemas import (
    ProgressTrackerRequest, PipelineStage, AgentStatus, QualityGateStatus, SLAStatus
)
from core.state_management.state_manager import state_manager
from core.state_management.models import AgentStateStatus
from datetime import datetime, date, timedelta
import json

def create_test_pipeline_state(session_id: str, employee_id: str):
    """Crear estado simulado del pipeline para testing"""
    
    # 1. Crear contexto del empleado
    employee_context_data = {
        "employee_id": employee_id,
        "employee_data": {
            "first_name": "MarÃ­a",
            "last_name": "FernÃ¡ndez",
            "email": "maria.fernandez@empresa.com",
            "department": "Engineering",
            "position": "Senior Software Engineer"
        },
        "started_at": datetime.utcnow() - timedelta(minutes=25),  # Pipeline iniciado hace 25 minutos
        "phase": "processing_pipeline"
    }
    
    # Crear contexto si no existe
    try:
        existing_context = state_manager.get_employee_context(session_id)
        if not existing_context:
            state_manager.create_employee_context(employee_context_data, session_id)
    except:
        state_manager.create_employee_context(employee_context_data, session_id)
    
    # 2. Simular estado de Data Aggregator Agent (COMPLETADO)
    state_manager.update_agent_state(
        "data_aggregator_agent",
        AgentStateStatus.COMPLETED,
        {
            "aggregation_completed": True,
            "overall_quality_score": 78.5,
            "validation_passed": True,
            "ready_for_sequential": True,
            "completeness_score": 85.0,
            "consistency_score": 82.0,
            "processing_time": 4.2
        },
        session_id
    )
    
    # 3. Simular estado de IT Provisioning Agent (COMPLETADO)
    state_manager.update_agent_state(
        "it_provisioning_agent",
        AgentStateStatus.COMPLETED,
        {
            "credentials_created": True,
            "system_access_configured": True,
            "equipment_assigned": True,
            "security_clearance_assigned": True,
            "provisioning_success_rate": 92.0,
            "security_compliance_score": 96.0,
            "processing_time": 8.7
        },
        session_id
    )
    
    # 4. Simular estado de Contract Management Agent (PROCESSING)
    state_manager.update_agent_state(
        "contract_management_agent",
        AgentStateStatus.PROCESSING,
        {
            "contract_generated": True,
            "legal_validation_passed": False,  # AÃºn en proceso
            "signature_process_complete": False,
            "document_archived": False,
            "compliance_score": 88.0,
            "processing_time": 12.3
        },
        session_id
    )
    
    # 5. Simular estado de Meeting Coordination Agent (WAITING)
    state_manager.update_agent_state(
        "meeting_coordination_agent",
        AgentStateStatus.IDLE,
        {
            "status": "waiting_for_contract_completion"
        },
        session_id
    )
    
    print(f"âœ… Estado del pipeline simulado creado para session {session_id}")
    return True

def create_test_progress_tracker_request():
    """Crear solicitud de tracking con datos de testing"""
    
    session_id = "test_progress_session_" + datetime.now().strftime("%Y%m%d_%H%M%S")
    employee_id = "EMP_TRACK_001"
    
    # Crear estado simulado del pipeline
    create_test_pipeline_state(session_id, employee_id)
    
    return ProgressTrackerRequest(
        employee_id=employee_id,
        session_id=session_id,
        monitoring_scope="full_pipeline",
        include_quality_gates=True,
        include_sla_monitoring=True,
        include_escalation_check=True,
        target_stages=[
            PipelineStage.DATA_AGGREGATION.value,
            PipelineStage.IT_PROVISIONING.value,
            PipelineStage.CONTRACT_MANAGEMENT.value,
            PipelineStage.MEETING_COORDINATION.value
        ],
        target_agents=[
            "data_aggregator_agent",
            "it_provisioning_agent", 
            "contract_management_agent",
            "meeting_coordination_agent"
        ],
        detailed_metrics=True,
        include_predictions=True,
        include_recommendations=True
    )

def test_progress_tracker_agent():
    """Test completo del Progress Tracker Agent"""
    print("ğŸ”„ TESTING PROGRESS TRACKER AGENT + PIPELINE MONITORING")
    print("=" * 75)
    
    try:
        # Test 1: Crear y verificar Progress Tracker Agent
        print("\nğŸ“ Test 1: Inicializar Progress Tracker Agent")
        tracker = ProgressTrackerAgent()
        print("âœ… Progress Tracker Agent creado exitosamente")
        
        # Verificar integraciÃ³n con State Management
        overview = state_manager.get_system_overview()
        print(f"âœ… Agentes registrados en sistema: {overview['registered_agents']}")
        print(f"âœ… Estado del tracker: {overview['agents_status'].get('progress_tracker_agent', 'no encontrado')}")
        
        # Verificar configuraciÃ³n de monitoreo
        config_validation = tracker.validate_monitoring_configuration()
        print(f"âœ… ConfiguraciÃ³n de monitoreo vÃ¡lida: {config_validation['configuration_valid']}")
        print(f"âœ… Quality gates configurados: {config_validation['quality_gates_configured']}")
        print(f"âœ… Configuraciones SLA: {config_validation['sla_configurations']}")
        print(f"âœ… Reglas de escalaciÃ³n: {config_validation['escalation_rules']}")
        
        if not config_validation['configuration_valid']:
            print("âš ï¸ Issues de configuraciÃ³n:")
            for issue in config_validation['validation_issues']:
                print(f"   - {issue}")
        
        # Test 2: Crear solicitud de tracking
        print("\nğŸ“ Test 2: Crear solicitud de tracking del pipeline secuencial")
        tracking_request = create_test_progress_tracker_request()
        print(f"âœ… Solicitud creada para empleado: {tracking_request.employee_id}")
        print(f"âœ… Session ID: {tracking_request.session_id}")
        print(f"âœ… Scope de monitoreo: {tracking_request.monitoring_scope}")
        print(f"âœ… Etapas objetivo: {len(tracking_request.target_stages)}")
        print(f"âœ… Agentes objetivo: {len(tracking_request.target_agents)}")
        
        # Verificar estado inicial del pipeline
        print("\nğŸ“Š Verificando estado inicial del pipeline simulado:")
        session_id = tracking_request.session_id
        
        # Verificar cada agente del pipeline
        pipeline_agents = [
            ("data_aggregator_agent", "Data Aggregator"),
            ("it_provisioning_agent", "IT Provisioning"),
            ("contract_management_agent", "Contract Management"),
            ("meeting_coordination_agent", "Meeting Coordination")
        ]
        
        for agent_id, agent_name in pipeline_agents:
            agent_state = state_manager.get_agent_state(agent_id, session_id)
            if agent_state:
                print(f"   ğŸ¤– {agent_name}: {agent_state.status} - {len(agent_state.data)} datos")
            else:
                print(f"   ğŸ¤– {agent_name}: No encontrado")
        
        # Test 3: Ejecutar tracking completo
        print("\nğŸ“ Test 3: Ejecutar tracking completo del pipeline")
        print("ğŸš€ Iniciando monitoreo de progreso...")
        start_time = datetime.now()
        
        tracking_result = tracker.track_pipeline_progress(tracking_request)
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        print(f"â±ï¸ Tiempo total de tracking: {processing_time:.2f} segundos")
        print(f"âœ… Tracking exitoso: {tracking_result['success']}")
        print(f"âœ… Tracker ID: {tracking_result.get('tracker_id', 'No generado')}")
        print(f"âœ… Estado de tracking: {tracking_result.get('tracking_status', 'unknown')}")
        
        tracker_id = tracking_result.get('tracker_id')
        
        # Test 4: Verificar monitoreo de step completion
        print("\nğŸ“ Test 4: Verificar monitoreo de completitud de pasos")
        stages_monitored = tracking_result.get('stages_monitored', 0)
        progress_snapshot = tracking_result.get('progress_snapshot')
        
        print(f"âœ… Etapas monitoreadas: {stages_monitored}")
        
        if progress_snapshot:
            print(f"âœ… Progreso general: {progress_snapshot.get('overall_progress_percentage', 0):.1f}%")
            print(f"âœ… Etapa actual: {progress_snapshot.get('current_stage', 'unknown')}")
            print(f"âœ… Tiempo estimado completitud: {progress_snapshot.get('estimated_completion_time', 'N/A')}")
            
            # Detalles por etapa
            print("ğŸ“‹ Estado por etapa del pipeline:")
            stage_order = ["data_aggregation", "it_provisioning", "contract_management", "meeting_coordination"]
            
            for stage in stage_order:
                status_emoji = "âœ…" if stage in ["data_aggregation", "it_provisioning"] else "ğŸ”„" if stage == "contract_management" else "â³"
                print(f"   {status_emoji} {stage.replace('_', ' ').title()}")
        
        # Test 5: Verificar quality gates
        print("\nğŸ“ Test 5: Verificar evaluaciÃ³n de quality gates")
        quality_gates_evaluated = tracking_result.get('quality_gates_evaluated', 0)
        quality_gate_results = tracking_result.get('quality_gate_results', [])
        
        print(f"âœ… Quality gates evaluados: {quality_gates_evaluated}")
        
        gates_passed = 0
        gates_failed = 0
        gates_pending = 0
        
        # REEMPLAZAR POR:
        for gate_result in quality_gate_results:
            if isinstance(gate_result, dict):
                gate_data = gate_result.get('gate_result', {})
                if gate_data is not None and isinstance(gate_data, dict):
                    if gate_data.get('passed', False):
                        gates_passed += 1
                    elif gate_data.get('status') == 'failed':
                        gates_failed += 1
                    else:
                        gates_pending += 1
                else:
                    gates_pending += 1
            else:
                gates_pending += 1
        
        print(f"âœ… Gates aprobados: {gates_passed}")
        print(f"âœ… Gates fallidos: {gates_failed}")  
        print(f"âœ… Gates pendientes: {gates_pending}")
        
        # REEMPLAZAR POR:
        if quality_gate_results:
            print("ğŸ“‹ Detalles de quality gates:")
            for i, gate_result in enumerate(quality_gate_results[:3]):  # Mostrar primeros 3
                if isinstance(gate_result, dict):
                    gate_data = gate_result.get('gate_result', {})
                    if gate_data is not None and isinstance(gate_data, dict):
                        status = "âœ… PASSED" if gate_data.get('passed') else "âŒ FAILED" if gate_data.get('status') == 'failed' else "â³ PENDING"
                        score = gate_data.get('overall_score', 0)
                        print(f"   {status} Gate {i+1}: Score {score:.1f}%")
                    else:
                        print(f"   â³ PENDING Gate {i+1}: No data available")
                else:
                    print(f"   â³ PENDING Gate {i+1}: Invalid format")
        
        # Test 6: Verificar monitoreo de SLA
        print("\nğŸ“ Test 6: Verificar monitoreo de SLA y cumplimiento")
        sla_results = tracking_result.get('sla_monitoring_results', [])
        sla_breaches = tracking_result.get('sla_breaches_detected', 0)
        
        print(f"âœ… Resultados SLA obtenidos: {len(sla_results)}")
        print(f"âœ… Breaches detectados: {sla_breaches}")
        
        # Analizar estado de SLAs
        on_time_stages = 0
        at_risk_stages = 0
        breached_stages = 0
        
        for sla_result in sla_results:
            status = sla_result.get('status', 'unknown')
            if status == 'on_time':
                on_time_stages += 1
            elif status == 'at_risk':
                at_risk_stages += 1
            elif status == 'breached':
                breached_stages += 1
        
        print(f"ğŸ“Š SLA Status:")
        print(f"   âœ… On time: {on_time_stages} etapas")
        print(f"   âš ï¸ At risk: {at_risk_stages} etapas") 
        print(f"   ğŸš¨ Breached: {breached_stages} etapas")
        
        # Mostrar detalles de SLA por etapa
        if sla_results:
            print("ğŸ“‹ Detalles de SLA por etapa:")
            for sla_result in sla_results[:4]:  # Mostrar todas las etapas
                stage = sla_result.get('stage', 'unknown')
                status = sla_result.get('status', 'unknown')
                elapsed = sla_result.get('elapsed_time_minutes', 0)
                target = sla_result.get('target_duration_minutes', 0)
                
                status_emoji = "âœ…" if status == "on_time" else "âš ï¸" if status == "at_risk" else "ğŸš¨"
                print(f"   {status_emoji} {stage}: {elapsed:.1f}min / {target}min target")
        
        # Test 7: Verificar escalaciones
        print("\nğŸ“ Test 7: Verificar sistema de escalaciones")
        escalations_triggered = tracking_result.get('escalations_triggered', 0)
        escalation_events = tracking_result.get('escalation_events', [])
        escalation_required = tracking_result.get('escalation_required', False)
        
        print(f"âœ… Escalaciones detectadas: {escalations_triggered}")
        print(f"âœ… EscalaciÃ³n requerida: {'SÃ­' if escalation_required else 'No'}")
        
        if escalation_events:
            print("ğŸš¨ Eventos de escalaciÃ³n:")
            for event in escalation_events[:3]:  # Mostrar primeros 3
                escalation_type = event.get('escalation_type', 'unknown')
                escalation_level = event.get('escalation_level', 'unknown')
                trigger_reason = event.get('trigger_reason', 'No reason provided')
                print(f"   ğŸ”” {escalation_level.upper()} - {escalation_type}: {trigger_reason}")
        
        # Test 8: Verificar mÃ©tricas de salud del pipeline
        print("\nğŸ“ Test 8: Verificar mÃ©tricas de salud del pipeline")
        pipeline_health_score = tracking_result.get('pipeline_health_score', 0)
        completion_confidence = tracking_result.get('completion_confidence', 0)
        pipeline_blocked = tracking_result.get('pipeline_blocked', False)
        requires_manual_intervention = tracking_result.get('requires_manual_intervention', False)
        
        print(f"âœ… Score de salud del pipeline: {pipeline_health_score:.1f}%")
        print(f"âœ… Confianza de completitud: {completion_confidence:.1%}")
        print(f"âœ… Pipeline bloqueado: {'SÃ­' if pipeline_blocked else 'No'}")
        print(f"âœ… Requiere intervenciÃ³n manual: {'SÃ­' if requires_manual_intervention else 'No'}")
        
        # Evaluar salud general
        health_status = "EXCELENTE" if pipeline_health_score >= 85 else "BUENO" if pipeline_health_score >= 70 else "NECESITA ATENCIÃ“N" if pipeline_health_score >= 50 else "CRÃTICO"
        print(f"ğŸ“Š Estado de salud general: {health_status}")
        
        estimated_time_remaining = tracking_result.get('estimated_time_remaining_minutes', 0)
        if estimated_time_remaining:
            print(f"â° Tiempo estimado restante: {estimated_time_remaining:.1f} minutos")
        
        # Test 9: Verificar insights actionables
        print("\nğŸ“ Test 9: Verificar insights y recomendaciones")
        immediate_actions = tracking_result.get('immediate_actions_required', [])
        recommendations = tracking_result.get('recommendations', [])
        risk_mitigations = tracking_result.get('risk_mitigation_suggestions', [])
        
        print(f"âœ… Acciones inmediatas identificadas: {len(immediate_actions)}")
        print(f"âœ… Recomendaciones generadas: {len(recommendations)}")
        print(f"âœ… Sugerencias de mitigaciÃ³n: {len(risk_mitigations)}")
        
        if immediate_actions:
            print("ğŸš¨ Acciones inmediatas requeridas:")
            for action in immediate_actions[:3]:  # Mostrar primeras 3
                print(f"   - {action}")
        
        if recommendations:
            print("ğŸ’¡ Recomendaciones:")
            for rec in recommendations[:3]:  # Mostrar primeras 3
                print(f"   - {rec}")
        
        # Test 10: Verificar estado en State Management
        print("\nğŸ“ Test 10: Verificar estado en Common State Management")
        if session_id:
            context = state_manager.get_employee_context(session_id)
            if context:
                print(f"âœ… Contexto encontrado para empleado: {context.employee_id}")
                print(f"âœ… Fase actual: {context.phase}")
                print(f"âœ… Datos procesados: {'SÃ­' if context.processed_data else 'No'}")
                
                # Verificar datos de tracking en contexto
                processed_data = context.processed_data
                if processed_data and "progress_tracking_completed" in processed_data:
                    print(f"âœ… Tracking registrado en contexto: {processed_data['progress_tracking_completed']}")
                    print(f"âœ… Pipeline health score: {processed_data.get('pipeline_health_score', 0):.1f}%")
                    print(f"âœ… Pipeline bloqueado: {processed_data.get('pipeline_blocked', False)}")
                else:
                    print("âš ï¸ Datos de tracking no encontrados en contexto")
            else:
                print("âš ï¸ No se encontrÃ³ contexto en State Management")
        
        # Test 11: Test de herramientas individuales
        print("\nğŸ“ Test 11: Verificar herramientas de tracking individualmente")
        try:
            # Test step completion monitor
            print("   ğŸ”§ Testing step_completion_monitor_tool...")
            from agents.progress_tracker.tools import step_completion_monitor_tool
            
            step_test = step_completion_monitor_tool.invoke({
                "session_id": session_id,
                "detailed_analysis": True
            })
            print(f"      âœ… Step Completion Monitor: {step_test.get('success', False)}")
            print(f"         Etapas monitoreadas: {step_test.get('stages_monitored', 0)}")
            
            # Test quality gate validator  
            print("   ğŸ”§ Testing quality_gate_validator_tool...")
            from agents.progress_tracker.tools import quality_gate_validator_tool
            
            gate_test = quality_gate_validator_tool.invoke({
                "session_id": session_id,
                "stage": "data_aggregation"
            })
            print(f"      âœ… Quality Gate Validator: {gate_test.get('success', False)}")
            if gate_test.get('success'):
                gate_result = gate_test.get('gate_result', {})
                print(f"         Gate passed: {gate_result.get('passed', False)}")
                print(f"         Overall score: {gate_result.get('overall_score', 0):.1f}%")
            
            # Test SLA monitor
            print("   ğŸ”§ Testing sla_monitor_tool...")
            from agents.progress_tracker.tools import sla_monitor_tool
            
            sla_test = sla_monitor_tool.invoke({
                "session_id": session_id,
                "include_predictions": True
            })
            print(f"      âœ… SLA Monitor: {sla_test.get('success', False)}")
            print(f"         SLA compliance: {sla_test.get('overall_sla_compliance', 0):.1f}%")
            
            print("âœ… Herramientas de tracking funcionando correctamente")
            
        except Exception as e:
            print(f"âš ï¸ Error en test de herramientas: {e}")
        
        # Test 12: Test de reporte de salud
        print("\nğŸ“ Test 12: Test de reporte de salud del pipeline")
        try:
            health_report = tracker.get_pipeline_health_report(session_id)
            
            if health_report.get('health_report_generated'):
                print("âœ… Reporte de salud generado:")
                print(f"   ğŸ“Š Pipeline health score: {health_report.get('pipeline_health_score', 0):.1f}%")
                print(f"   ğŸ“ˆ Completion confidence: {health_report.get('completion_confidence', 0):.1%}")
                print(f"   ğŸš¨ Pipeline status: {health_report.get('pipeline_status', 'unknown')}")
                print(f"   ğŸ“ Immediate actions: {len(health_report.get('immediate_actions', []))}")
                print(f"   ğŸ’¡ Recommendations: {len(health_report.get('recommendations', []))}")
            else:
                print(f"âš ï¸ Error generando reporte: {health_report.get('error', 'Unknown')}")
        
        except Exception as e:
            print(f"âš ï¸ Error en reporte de salud: {e}")
        
        # Test 13: Verificar integraciÃ³n completa del sistema
        print("\nğŸ“ Test 13: Verificar integraciÃ³n completa del sistema")
        
        # Verificar capacidades del agente
        agent_capabilities = tracker.monitoring_rules
        print(f"âœ… Quality gates configurados: {len(agent_capabilities.quality_gates)}")
        print(f"âœ… SLA configurations: {len(agent_capabilities.sla_configurations)}")  
        print(f"âœ… Escalation rules: {len(agent_capabilities.escalation_rules)}")
        
        # Verificar estado de tracking
        if tracker_id:
            tracking_status = tracker.get_tracking_status(tracker_id)
            if tracking_status.get('found'):
                print(f"âœ… Tracking status encontrado: {tracking_status.get('status', 'unknown')}")
            else:
                print("âš ï¸ Tracking status no encontrado")
        
        # Resumen final
        print("\nğŸ‰ PROGRESS TRACKER AGENT INTEGRATION TEST COMPLETADO")
        print("=" * 65)
        
        # Calcular score de Ã©xito general
        success_indicators = [
            tracking_result['success'],
            pipeline_health_score >= 60.0,  # Salud mÃ­nima aceptable
            not pipeline_blocked,            # Pipeline no bloqueado
            stages_monitored >= 3,           # Al menos 3 etapas monitoreadas
            quality_gates_evaluated > 0,     # Quality gates evaluados
            len(sla_results) > 0,           # SLA monitoring funcionando
            config_validation['configuration_valid']  # ConfiguraciÃ³n vÃ¡lida
        ]
        
        success_rate = (sum(success_indicators) / len(success_indicators)) * 100
        
        print(f"âœ… PROGRESS TRACKER AGENT: {'EXITOSO' if success_rate >= 75 else 'NECESITA REVISIÃ“N'}")
        print(f"âœ… Score de Ã©xito: {success_rate:.1f}%")
        print(f"âœ… Tiempo de procesamiento: {processing_time:.2f}s")
        print(f"âœ… Pipeline health score: {pipeline_health_score:.1f}%")
        print(f"âœ… Etapas monitoreadas: {stages_monitored}")
        print(f"âœ… Quality gates evaluados: {quality_gates_evaluated}")
        print(f"âœ… SLA breaches detectados: {sla_breaches}")
        print(f"âœ… Escalaciones disparadas: {escalations_triggered}")
        print(f"âœ… ConfiguraciÃ³n vÃ¡lida: {'SÃ­' if config_validation['configuration_valid'] else 'No'}")
        print(f"âœ… State Management: INTEGRADO")
        print(f"âœ… LangFuse Observability: ACTIVA")
        
        return True, {
            "tracker_id": tracker_id,
            "session_id": session_id,
            "success_rate": success_rate,
            "processing_time": processing_time,
            "pipeline_health_score": pipeline_health_score,
            "stages_monitored": stages_monitored,
            "quality_gates_evaluated": quality_gates_evaluated,
            "sla_breaches": sla_breaches,
            "escalations_triggered": escalations_triggered,
            "pipeline_blocked": pipeline_blocked
        }
        
    except Exception as e:
        print(f"\nâŒ ERROR EN TEST DE PROGRESS TRACKER: {e}")
        import traceback
        traceback.print_exc()
        return False, {"error": str(e)}

def test_monitoring_rules_engine():
    """Test especÃ­fico del motor de reglas de monitoreo"""
    print("\nğŸ” TESTING MONITORING RULES ENGINE")
    print("=" * 50)
    
    try:
        from agents.progress_tracker.monitoring_rules import monitoring_rules_engine
        
        # Test quality gates
        print("   ğŸ“‹ Testing quality gates...")
        data_agg_gate = monitoring_rules_engine.get_quality_gate(PipelineStage.DATA_AGGREGATION)
        if data_agg_gate:
            print(f"      âœ… Data Aggregation Gate: {data_agg_gate.gate_name}")
            print(f"         Required fields: {len(data_agg_gate.required_fields)}")
            print(f"         Quality thresholds: {len(data_agg_gate.quality_thresholds)}")
        
        # Test SLA configurations
        print("   â° Testing SLA configurations...")
        it_sla = monitoring_rules_engine.get_sla_configuration(PipelineStage.IT_PROVISIONING)
        if it_sla:
            print(f"      âœ… IT Provisioning SLA: Target {it_sla.target_duration_minutes}min")
            print(f"         Breach threshold: {it_sla.breach_threshold_minutes}min")
        
        # Test escalation rules
        print("   ğŸš¨ Testing escalation rules...")
        escalation_rules = monitoring_rules_engine.get_applicable_escalation_rules()
        print(f"      âœ… Escalation rules configured: {len(escalation_rules)}")
        
        # Test validation
        print("   âœ… Testing configuration validation...")
        validation_issues = monitoring_rules_engine.validate_rule_consistency()
        print(f"      âœ… Validation issues: {len(validation_issues)}")
        
        if validation_issues:
            print("      âš ï¸ Issues encontrados:")
            for issue in validation_issues[:3]:
                print(f"         - {issue}")
        
        return len(validation_issues) == 0
        
    except Exception as e:
        print(f"âŒ Error en monitoring rules engine: {e}")
        return False

def test_quality_gate_individual():
    """Test individual de quality gate validation"""
    print("\nğŸ” TESTING INDIVIDUAL QUALITY GATE VALIDATION")
    print("=" * 50)
    
    try:
        from agents.progress_tracker.tools import quality_gate_validator_tool
        
        # Test con datos simulados
        mock_agent_output = {
            "overall_quality_score": 75.0,
            "completeness_score": 82.0,
            "consistency_score": 78.0,
            "validation_passed": True,
            "aggregation_completed": True,
            "ready_for_sequential": True
        }
        
        gate_result = quality_gate_validator_tool.invoke({
            "session_id": "test_quality_gate",
            "stage": "data_aggregation",
            "agent_output": mock_agent_output
        })
        
        print(f"âœ… Quality gate validation: {gate_result.get('success', False)}")
        
        if gate_result.get('success'):
            validation_summary = gate_result.get('validation_summary', {})
            print(f"   Gate passed: {validation_summary.get('gate_passed', False)}")
            print(f"   Overall score: {validation_summary.get('overall_score', 0):.1f}%")
            print(f"   Critical issues: {validation_summary.get('critical_issues', 0)}")
        
        return gate_result.get('success', False)
        
    except Exception as e:
        print(f"âŒ Error en quality gate test: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ INICIANDO TESTS COMPLETOS DEL PROGRESS TRACKER AGENT")
    print("=" * 70)
    
    # Test principal
    success, main_result = test_progress_tracker_agent()
    
    # Test de monitoring rules engine
    rules_success = test_monitoring_rules_engine()
    
    # Test individual de quality gate
    gate_success = test_quality_gate_individual()
    
    # Resumen final
    print("\n" + "=" * 70)
    print("ğŸ“Š RESUMEN FINAL DE TESTS")
    print("=" * 70)
    
    if success:
        print("ğŸ‰ PROGRESS TRACKER AGENT COMPLETAMENTE FUNCIONAL")
        print(f"âœ… Success Rate: {main_result.get('success_rate', 0):.1f}%")
        print(f"âœ… Tiempo de procesamiento: {main_result.get('processing_time', 0):.2f}s")
        print(f"âœ… Pipeline health score: {main_result.get('pipeline_health_score', 0):.1f}%")
        print(f"âœ… Etapas monitoreadas: {main_result.get('stages_monitored', 0)}")
        print(f"âœ… Quality gates evaluados: {main_result.get('quality_gates_evaluated', 0)}")
        print(f"âœ… SLA breaches detectados: {main_result.get('sla_breaches', 0)}")
        print(f"âœ… Escalaciones disparadas: {main_result.get('escalations_triggered', 0)}")
        print(f"âœ… Pipeline bloqueado: {main_result.get('pipeline_blocked', False)}")
        print(f"âœ… Monitoring Rules Engine: {'âœ…' if rules_success else 'âŒ'}")
        print(f"âœ… Quality Gate Validation: {'âœ…' if gate_success else 'âŒ'}")
        print(f"âœ… Tracker ID: {main_result.get('tracker_id', 'N/A')}")
        
        print("\nğŸ¯ RESULTADO: PROGRESS TRACKER & QUALITY ASSURANCE OPERATIVO")
        print("ğŸš€ MONITOREO DE PIPELINE SECUENCIAL COMPLETAMENTE FUNCIONAL")
        print("   ğŸ“‹ Monitoreo: Step Completion + Quality Gates + SLA + Escalaciones")
        print("   âœ… Listo para supervisar: IT Provisioning â†’ Contract Management â†’ Meeting Coordination")
        print("   ğŸ”§ Progress Tracker integrado y listo para orchestrator")
        
    else:
        print("ğŸ’¥ PROGRESS TRACKER AGENT REQUIERE REVISIÃ“N")
        print(f"âŒ Error: {main_result.get('error', 'Unknown')}")
        print("\nğŸ”§ REQUIERE DEBUGGING ANTES DE INTEGRAR AL ORCHESTRATOR")
    
    print("\n" + "=" * 70)