from typing_extensions import TypedDict
from typing import Dict, Any, List, Optional, Annotated
from datetime import datetime, timedelta, timezone
import json
import asyncio
from enum import Enum
import operator
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from loguru import logger

# Imports de nuestros agentes y state management
from core.state_management.state_manager import state_manager
from core.state_management.models import AgentStateStatus, OnboardingPhase
from core.observability import observability_manager
from shared.models import Priority

# Import de agentes existentes
from agents.initial_data_collection.agent import InitialDataCollectionAgent
from agents.confirmation_data.agent import ConfirmationDataAgent
from agents.documentation.agent import DocumentationAgent
from agents.data_aggregator.agent import DataAggregatorAgent
from agents.it_provisioning.agent import ITProvisioningAgent
from agents.contract_management.agent import ContractManagementAgent
from agents.meeting_coordination.agent import MeetingCoordinationAgent
from agents.progress_tracker.agent import ProgressTrackerAgent
from agents.data_aggregator.schemas import AggregationRequest, ValidationLevel

# Import de schemas y tools del orchestrator
from .schemas import (
    OrchestrationState, OrchestrationPhase, AgentType,
    TaskStatus, WorkflowStep, OrchestrationResult,
    SequentialPipelinePhase, PipelineAgentResult, SequentialPipelineRequest,
    SequentialPipelineResult, ErrorHandlingResult
)
from .tools import (
    pattern_selector_tool, task_distributor_tool,
    state_coordinator_tool, progress_monitor_tool
)

def utc_now() -> datetime:
    """Obtener datetime UTC timezone-aware"""
    return datetime.now(timezone.utc)

def utc_now_iso() -> str:
    """Obtener datetime UTC como string ISO"""
    return utc_now().isoformat()

# ‚úÖ WorkflowState CON ERROR HANDLING
class WorkflowState(TypedDict, total=False):
    """Estado SIMPLE con Error Handling integrado"""
    # Core fields
    session_id: str
    employee_id: str
    orchestration_id: str
    current_phase: str
    
    # Data fields
    consolidated_data: dict
    pipeline_input_data: dict
    pipeline_results: dict
    
    # Control fields
    errors: list
    progress_percentage: float
    messages: Annotated[list, operator.add]
    
    # ‚úÖ ERROR HANDLING FIELDS
    error_handling_active: bool
    error_handling_results: dict
    quality_score_issues: list
    agent_failure_count: int

class DataCollectionWorkflow:
    """Workflow CON ERROR HANDLING para DATA COLLECTION HUB"""

    def __init__(self):
        self.graph = None
        self.agents = {
            AgentType.INITIAL_DATA_COLLECTION.value: None,
            AgentType.CONFIRMATION_DATA.value: None,
            AgentType.DOCUMENTATION.value: None
        }
        self.data_aggregator = None
        self._setup_agents()
        self._build_graph()

    def _setup_agents(self):
        """Inicializar agentes del sistema"""
        try:
            self.agents[AgentType.INITIAL_DATA_COLLECTION.value] = InitialDataCollectionAgent()
            self.agents[AgentType.CONFIRMATION_DATA.value] = ConfirmationDataAgent()
            self.agents[AgentType.DOCUMENTATION.value] = DocumentationAgent()
            self.data_aggregator = DataAggregatorAgent()
            logger.info("‚úÖ Agentes del DATA COLLECTION HUB inicializados")
        except Exception as e:
            logger.error(f"‚ùå Error inicializando agentes: {e}")
            raise

    def _build_graph(self):
        """Arquitectura SIMPLE con Error Handling integrado"""
        try:
            workflow = StateGraph(WorkflowState)

            # Nodos principales
            workflow.add_node("initialize", self._initialize_orchestration)
            workflow.add_node("execute_real_collection", self._execute_real_data_collection)
            workflow.add_node("aggregate_real_data", self._aggregate_real_data_collection_results)
            workflow.add_node("validate_quality", self._validate_real_quality)
            workflow.add_node("prepare_sequential", self._prepare_for_sequential_pipeline)
            workflow.add_node("finalize", self._finalize_orchestration)
            workflow.add_node("handle_errors", self._handle_workflow_errors)

            # Flujo principal
            workflow.set_entry_point("initialize")
            workflow.add_edge("initialize", "execute_real_collection")
            workflow.add_edge("execute_real_collection", "aggregate_real_data")
            workflow.add_edge("aggregate_real_data", "validate_quality")
            
            # ‚úÖ CONDITIONAL EDGE PARA ERROR HANDLING
            workflow.add_conditional_edges(
                "validate_quality",
                self._should_proceed_or_handle_errors,
                {
                    "sequential_pipeline": "prepare_sequential", 
                    "finalize": "finalize",
                    "handle_errors": "handle_errors"  # ‚úÖ NUEVA RUTA ERROR HANDLING
                }
            )
            
            workflow.add_edge("prepare_sequential", "finalize")
            workflow.add_edge("finalize", END)
            workflow.add_edge("handle_errors", END)

            self.graph = workflow.compile()
            logger.info("‚úÖ DataCollection Workflow CON ERROR HANDLING construido")
        except Exception as e:
            logger.error(f"‚ùå Error construyendo workflow: {e}")
            raise

    async def _initialize_orchestration(self, state: WorkflowState) -> WorkflowState:
        """Inicializar orquestaci√≥n con Error Handling"""
        try:
            if not state.get("session_id"):
                state["session_id"] = f"session_{utc_now().strftime('%Y%m%d_%H%M%S')}"
            
            state["current_phase"] = OrchestrationPhase.INITIATED.value
            state["progress_percentage"] = 0.0
            state["errors"] = []
            state["messages"] = [AIMessage(content=f"Orquestaci√≥n REAL iniciada para empleado {state['employee_id']}")]
            
            # ‚úÖ INICIALIZAR ERROR HANDLING
            state["error_handling_active"] = False
            state["error_handling_results"] = {}
            state["quality_score_issues"] = []
            state["agent_failure_count"] = 0
            
            logger.info(f"‚úÖ Orquestaci√≥n REAL inicializada: {state.get('session_id')}")
            return state
        except Exception as e:
            logger.error(f"‚ùå Error inicializando: {e}")
            state["errors"] = [str(e)]
            return state

    async def _execute_real_data_collection(self, state: WorkflowState) -> WorkflowState:
        """Ejecutar agentes CON DATOS REALES - ARREGLADO"""
        try:
            logger.info("üîÑ Ejecutando recolecci√≥n CON DATOS REALES")
            
            employee_data_real = state.get("employee_data", {})
            contract_data_real = state.get("contract_data", {})
            documents_real = state.get("documents", [])
            session_id = state.get("session_id")
            
            agent_results = {}  # ‚úÖ INICIALIZAR
            successful_agents = 0
            failed_agents = 0

            # ‚úÖ 1. INITIAL DATA COLLECTION REAL
            try:
                if self.agents[AgentType.INITIAL_DATA_COLLECTION.value]:
                    initial_request = {
                        "employee_id": state["employee_id"],
                        "session_id": session_id,
                        "employee_data": employee_data_real,
                        "processing_priority": "high"
                    }

                    initial_result = self.agents[AgentType.INITIAL_DATA_COLLECTION.value].process_request(initial_request)
                    
                    # ‚úÖ SIEMPRE GUARDAR RESULTADO - INCLUSO SI NO TIENE success=True
                    agent_results["initial_data_collection_agent"] = {
                        **(initial_result if initial_result else {}),
                        "agent_id": "initial_data_collection_agent",
                        "data_source": "real_employee_data",
                        "executed": True
                    }
                    
                    if initial_result and initial_result.get("success", False):
                        successful_agents += 1
                        logger.info("‚úÖ Initial Data Collection REAL - exitoso")
                    else:
                        failed_agents += 1
                        logger.warning("‚ö†Ô∏è Initial Data Collection REAL - fall√≥")
                            
            except Exception as e:
                logger.error(f"‚ùå Initial Data Collection error: {e}")
                agent_results["initial_data_collection_agent"] = {
                    "success": False,
                    "agent_id": "initial_data_collection_agent", 
                    "error": str(e),
                    "executed": True
                }
                failed_agents += 1

            # ‚úÖ 2. CONFIRMATION DATA REAL
            try:
                if self.agents[AgentType.CONFIRMATION_DATA.value]:
                    confirmation_request = {
                        "employee_id": state["employee_id"],
                        "session_id": session_id,
                        "contract_data": contract_data_real,
                        "employee_context": employee_data_real
                    }

                    confirmation_result = self.agents[AgentType.CONFIRMATION_DATA.value].process_request(confirmation_request)
                    
                    # ‚úÖ SIEMPRE GUARDAR RESULTADO
                    agent_results["confirmation_data_agent"] = {
                        **(confirmation_result if confirmation_result else {}),
                        "agent_id": "confirmation_data_agent",
                        "data_source": "real_contract_data",
                        "executed": True
                    }
                    
                    if confirmation_result and confirmation_result.get("success", False):
                        successful_agents += 1
                        logger.info("‚úÖ Confirmation Data REAL - exitoso")
                    else:
                        failed_agents += 1
                        logger.warning("‚ö†Ô∏è Confirmation Data REAL - fall√≥")
                            
            except Exception as e:
                logger.error(f"‚ùå Confirmation Data error: {e}")
                agent_results["confirmation_data_agent"] = {
                    "success": False,
                    "agent_id": "confirmation_data_agent",
                    "error": str(e),
                    "executed": True
                }
                failed_agents += 1

            # ‚úÖ 3. DOCUMENTATION REAL
            try:
                if self.agents[AgentType.DOCUMENTATION.value]:
                    documentation_request = {
                        "employee_id": state["employee_id"],
                        "session_id": session_id,
                        "documents": documents_real,
                        "employee_context": employee_data_real
                    }

                    documentation_result = self.agents[AgentType.DOCUMENTATION.value].process_request(documentation_request)
                    
                    # ‚úÖ SIEMPRE GUARDAR RESULTADO
                    agent_results["documentation_agent"] = {
                        **(documentation_result if documentation_result else {}),
                        "agent_id": "documentation_agent",
                        "data_source": "real_documents",
                        "executed": True
                    }
                    
                    if documentation_result and documentation_result.get("success", False):
                        successful_agents += 1
                        logger.info("‚úÖ Documentation REAL - exitoso")
                    else:
                        failed_agents += 1
                        logger.warning("‚ö†Ô∏è Documentation REAL - fall√≥")
                            
            except Exception as e:
                logger.error(f"‚ùå Documentation error: {e}")
                agent_results["documentation_agent"] = {
                    "success": False,
                    "agent_id": "documentation_agent",
                    "error": str(e),
                    "executed": True
                }
                failed_agents += 1

            # ‚úÖ CR√çTICO: ASIGNAR AL STATE
            state["agent_results"] = agent_results
            state["agent_failure_count"] = failed_agents
            state["progress_percentage"] = 60.0

            logger.info(f"üìä Ejecuci√≥n REAL completada:")
            logger.info(f"   - Agentes exitosos: {successful_agents}/3")
            logger.info(f"   - Agentes fallidos: {failed_agents}/3")
            logger.info(f"   - Agent results guardados: {len(agent_results)}")
            
            return state

        except Exception as e:
            logger.error(f"‚ùå Error cr√≠tico en ejecuci√≥n real: {e}")
            state["errors"] = [str(e)]
            state["agent_failure_count"] = 3
            state["agent_results"] = {}  # ‚úÖ ASEGURAR QUE EXISTE
            return state
    # BUSCAR L√çNEA ~335 y REEMPLAZAR la funci√≥n completa:

    # ‚úÖ ARREGLAR LA FUNCI√ìN _aggregate_real_data_collection_results

    async def _aggregate_real_data_collection_results(self, state: WorkflowState) -> WorkflowState:
        """BYPASS COMPLETO DEL DATA AGGREGATOR - C√ÅLCULO DIRECTO"""
        try:
            logger.info("üîÑ BYPASS Data Aggregator - C√°lculo directo...")
            session_id = str(state.get("session_id", ""))
            agent_results = state.get("agent_results", {})
            
            logger.info(f"üìä Analizando {len(agent_results)} agentes directamente")
            
            # ‚úÖ CALCULAR QUALITY SCORE DIRECTAMENTE DE LOS AGENTES
            total_quality = 0.0
            successful_agents = 0
            
            for agent_key, agent_result in agent_results.items():
                agent_quality = 0.0
                
                if isinstance(agent_result, dict):
                    # ‚úÖ EXTRAER QUALITY SCORES ESPEC√çFICOS DE CADA AGENTE
                    if "validation_score" in agent_result:
                        agent_quality = max(agent_quality, agent_result["validation_score"])
                    
                    if "compliance_score" in agent_result:
                        agent_quality = max(agent_quality, agent_result["compliance_score"])
                    
                    if "quality_score" in agent_result:
                        agent_quality = max(agent_quality, agent_result["quality_score"])
                    
                    # ‚úÖ SI TIENE success=True, M√çNIMO 30%
                    if agent_result.get("success", False):
                        agent_quality = max(agent_quality, 30.0)
                    
                    # ‚úÖ SI TIENE DATOS ESTRUCTURADOS, +20%
                    if agent_result.get("structured_data") or agent_result.get("agent_output"):
                        agent_quality = max(agent_quality, 50.0)
                    
                    logger.info(f"   - {agent_key}: quality={agent_quality:.1f}%")
                    
                    if agent_quality > 0:
                        total_quality += agent_quality
                        successful_agents += 1
                else:
                    logger.warning(f"   - {agent_key}: resultado inv√°lido")

            # ‚úÖ CALCULAR QUALITY SCORE FINAL
            if successful_agents > 0:
                overall_quality_score = total_quality / successful_agents
            else:
                overall_quality_score = 0.0
            
            # ‚úÖ BONUS POR M√öLTIPLES AGENTES EXITOSOS
            if successful_agents >= 2:
                overall_quality_score += 10.0  # Bonus colaborativo
            
            if successful_agents == 3:
                overall_quality_score += 5.0   # Bonus completo
            
            # ‚úÖ LIMITAR A 100%
            overall_quality_score = min(overall_quality_score, 100.0)
            
            logger.info(f"üìä QUALITY SCORE DIRECTO: {overall_quality_score:.1f}% ({successful_agents}/3 agentes)")
            
            # ‚úÖ CREAR DATOS CONSOLIDADOS B√ÅSICOS
            consolidated_employee_data = {"employee_id": state["employee_id"]}
            
            # ‚úÖ EXTRAER DATOS DE AGENTES EXITOSOS
            for agent_result in agent_results.values():
                if isinstance(agent_result, dict):
                    # Extraer structured_data
                    if "structured_data" in agent_result:
                        struct_data = agent_result["structured_data"]
                        if isinstance(struct_data, dict):
                            for key, value in struct_data.items():
                                if isinstance(value, dict):
                                    consolidated_employee_data.update(value)
                    
                    # Extraer contractual_data
                    if "contractual_data" in agent_result:
                        contractual_data = agent_result["contractual_data"]
                        if isinstance(contractual_data, dict):
                            consolidated_employee_data.update(contractual_data)
                    
                    # Extraer agent_output
                    if "agent_output" in agent_result:
                        output_data = agent_result["agent_output"]
                        if isinstance(output_data, dict):
                            consolidated_employee_data.update(output_data)
            
            # ‚úÖ RESULTADO DIRECTO - NO DATA AGGREGATOR
            aggregation_result = {
                "success": overall_quality_score >= 25.0,
                "overall_quality_score": overall_quality_score,
                "ready_for_sequential_pipeline": overall_quality_score >= 40.0,
                "consolidated_data": consolidated_employee_data,
                "completeness_score": min(successful_agents * 33.33, 100.0),
                "consistency_score": overall_quality_score * 0.9,
                "validation_passed": overall_quality_score >= 30.0,
                "bypass_mode": True,
                "successful_agents": successful_agents,
                "total_agents": len(agent_results)
            }
            
            # ‚úÖ ACTUALIZAR STATE
            state["aggregation_result"] = aggregation_result
            state["data_quality_score"] = overall_quality_score
            state["ready_for_sequential_pipeline"] = overall_quality_score >= 40.0
            
            # ‚úÖ CONSOLIDATED DATA
            state["consolidated_data"] = {
                "aggregated_employee_data": consolidated_employee_data,
                "data_quality_metrics": {
                    "overall_quality": overall_quality_score,
                    "completeness": min(successful_agents * 33.33, 100.0),
                    "consistency": overall_quality_score * 0.9,
                    "aggregation_success": True,
                    "successful_agents": successful_agents,
                    "total_agents": len(agent_results),
                    "bypass_mode": True
                }
            }
            
            # ‚úÖ QUALITY ISSUES
            if overall_quality_score < 30.0:
                state["quality_score_issues"].append("low_quality_score_direct")
            
            state["progress_percentage"] = 85.0
            
            logger.info(f"‚úÖ BYPASS AGGREGATOR COMPLETADO:")
            logger.info(f"   - Quality Score: {overall_quality_score:.1f}%")
            logger.info(f"   - Ready for Pipeline: {overall_quality_score >= 40.0}")
            logger.info(f"   - Successful Agents: {successful_agents}/3")
            
            return state

        except Exception as e:
            logger.error(f"‚ùå Error en bypass aggregator: {e}")
            
            # ‚úÖ FALLBACK B√ÅSICO
            state["aggregation_result"] = {
                "success": False,
                "overall_quality_score": 20.0,
                "ready_for_sequential_pipeline": False,
                "error": str(e),
                "fallback_mode": True
            }
            state["data_quality_score"] = 20.0
            state["consolidated_data"] = {"aggregated_employee_data": {"employee_id": state["employee_id"]}}
            
            return state

    async def _validate_real_quality(self, state: WorkflowState) -> WorkflowState:
        """Validar calidad SIMPLE Y DIRECTA"""
        try:
            data_quality_score = state.get("data_quality_score", 0.0)
            agent_failure_count = state.get("agent_failure_count", 0)
            quality_issues = state.get("quality_score_issues", [])
            
            logger.info(f"üìä Validando calidad DIRECTA:")
            logger.info(f"   - Quality Score: {data_quality_score:.1f}%")
            logger.info(f"   - Agent Failures: {agent_failure_count}/3")
            logger.info(f"   - Quality Issues: {len(quality_issues)}")
            
            # ‚úÖ CRITERIOS SIMPLES Y CLAROS
            needs_error_handling = data_quality_score < 25.0 and agent_failure_count >= 2
            
            if needs_error_handling:
                state["next_workflow_phase"] = "handle_errors"
                state["error_handling_active"] = True
                logger.warning("üö® ERROR HANDLING NECESARIO - Quality muy baja + m√∫ltiples fallas")
            elif data_quality_score >= 40.0:
                state["next_workflow_phase"] = "sequential_pipeline"
                logger.info("‚úÖ Calidad BUENA - Sequential Pipeline")
            else:
                state["next_workflow_phase"] = "finalize"
                logger.info(f"‚ö†Ô∏è Calidad ACEPTABLE ({data_quality_score:.1f}%) - Finalizando")
                
            state["aggregation_validation_passed"] = data_quality_score >= 25.0
            
            return state

        except Exception as e:
            logger.error(f"‚ùå Error validando calidad: {e}")
            state["next_workflow_phase"] = "finalize"
            state["error_handling_active"] = False
            return state

    def _should_proceed_or_handle_errors(self, state: WorkflowState) -> str:
        """Decidir si proceder o activar Error Handling"""
        next_phase = state.get("next_workflow_phase", "finalize")
        logger.info(f"üîÑ Routing decision: {next_phase}")
        return next_phase

    async def _prepare_for_sequential_pipeline(self, state: WorkflowState) -> WorkflowState:
        """Preparar datos para Sequential Pipeline"""
        try:
            sequential_request_data = {
                "employee_id": state["employee_id"],
                "session_id": state.get("session_id"),
                "orchestration_id": state["orchestration_id"],
                "consolidated_data": state.get("consolidated_data", {}),
                "aggregation_result": state.get("aggregation_result", {}),
                "data_quality_score": state.get("data_quality_score", 0.0)
            }
            
            state["sequential_pipeline_request"] = sequential_request_data
            state["ready_for_sequential_execution"] = True
            state["progress_percentage"] = 90.0
            
            logger.info("‚úÖ Datos preparados para Sequential Pipeline")
            return state
        except Exception as e:
            logger.error(f"‚ùå Error preparando Sequential Pipeline: {e}")
            state["sequential_pipeline_request"] = {"employee_id": state["employee_id"]}
            state["ready_for_sequential_execution"] = False
            return state

    async def _finalize_orchestration(self, state: WorkflowState) -> WorkflowState:
        """Finalizar orquestraci√≥n CON RESULTADOS REALES"""
        try:
            agent_results = state.get("agent_results", {})
            data_quality_score = state.get("data_quality_score", 0.0)
            
            # ‚úÖ RESULTADO FINAL BASADO EN DATOS REALES
            final_success = (
                len([r for r in agent_results.values() if r.get("success", False)]) >= 2 and
                data_quality_score >= 30.0
            )
            
            final_result = {
                "orchestration_id": state["orchestration_id"],
                "session_id": state.get("session_id"),
                "employee_id": state["employee_id"],
                "success": final_success,  # ‚úÖ BASADO EN DATOS REALES
                "agent_results": agent_results,
                "consolidated_data": state.get("consolidated_data", {}),
                "aggregation_result": state.get("aggregation_result", {}),
                "data_quality_score": data_quality_score,  # ‚úÖ SCORE REAL
                "ready_for_sequential_execution": state.get("ready_for_sequential_execution", False),
                "sequential_pipeline_request": state.get("sequential_pipeline_request", {}),
                "errors": state.get("errors", []),
                "completion_status": "completed" if final_success else "completed_with_issues",
                "quality_issues_detected": state.get("quality_score_issues", []),
                "agent_failure_count": state.get("agent_failure_count", 0)
            }

            state["final_result"] = final_result
            
            logger.info(f"‚úÖ FINALIZE REAL: success={final_success}, quality={data_quality_score:.1f}%")
            return state

        except Exception as e:
            logger.error(f"‚ùå Error en finalize: {e}")
            # ‚úÖ RESULTADO DE ERROR REAL
            state["final_result"] = {
                "success": False,
                "agent_results": state.get("agent_results", {}),
                "orchestration_id": state.get("orchestration_id", "fallback"),
                "employee_id": state.get("employee_id", "fallback"),
                "data_quality_score": state.get("data_quality_score", 0.0),
                "errors": [str(e)]
            }
            return state

    async def _handle_workflow_errors(self, state: WorkflowState) -> WorkflowState:
        """Manejar errores del workflow - PREPARAR PARA ERROR HANDLING"""
        try:
            errors = state.get("errors", [])
            quality_issues = state.get("quality_score_issues", [])
            agent_results = state.get("agent_results", {})
            
            # ‚úÖ CONSOLIDAR INFORMACI√ìN PARA ERROR HANDLING
            error_summary = {
                "total_errors": len(errors),
                "quality_issues": quality_issues,
                "agent_failure_count": state.get("agent_failure_count", 0),
                "data_quality_score": state.get("data_quality_score", 0.0),
                "successful_agents": len([r for r in agent_results.values() if r.get("success", False)]),
                "failed_agents": [k for k, v in agent_results.items() if not v.get("success", False)]
            }
            
            # ‚úÖ RESULTADO QUE ACTIVAR√Å ERROR HANDLING EN ORCHESTRATOR
            error_result = {
                "orchestration_id": state["orchestration_id"],
                "session_id": state.get("session_id"),
                "employee_id": state["employee_id"],
                "success": False,  # ‚úÖ FALLA REAL
                "agent_results": agent_results,
                "consolidated_data": state.get("consolidated_data", {}),
                "aggregation_result": state.get("aggregation_result", {}),
                "data_quality_score": state.get("data_quality_score", 0.0),
                "ready_for_sequential_execution": False,
                "errors": errors + [f"Quality issues: {', '.join(quality_issues)}"],
                "completion_status": "failed_requires_error_handling",
                "error_summary": error_summary,
                "requires_error_handling": True  # ‚úÖ SE√ëAL CLARA
            }

            state["final_result"] = error_result
            state["current_phase"] = OrchestrationPhase.ERROR_HANDLING.value
            
            logger.warning(f"üö® Workflow ERROR HANDLING preparado:")
            logger.warning(f"   - Quality Score: {state.get('data_quality_score', 0.0):.1f}%")
            logger.warning(f"   - Failed Agents: {error_summary['agent_failure_count']}/3")
            logger.warning(f"   - Quality Issues: {len(quality_issues)}")
            
            return state

        except Exception as e:
            logger.error(f"‚ùå Error en error handling: {e}")
            state["final_result"] = {
                "success": False, 
                "agent_results": {}, 
                "errors": [str(e)],
                "requires_error_handling": True
            }
            return state

    # ‚úÖ REEMPLAZAR execute_workflow COMPLETO
    async def execute_workflow(self, orchestration_request: Dict[str, Any]) -> Dict[str, Any]:
        """BYPASS COMPLETO DE LANGGRAPH - EJECUCI√ìN LINEAL DIRECTA"""
        try:
            logger.info(f"üöÄ EJECUTANDO WORKFLOW DIRECTO (SIN LANGGRAPH): {orchestration_request['employee_id']}")
            
            session_id = orchestration_request.get("session_id", f"session_direct_{utc_now().strftime('%Y%m%d_%H%M%S')}")
            employee_id = orchestration_request["employee_id"]
            
            # ‚úÖ PASO 1: EJECUTAR AGENTES DIRECTAMENTE
            logger.info("üîÑ PASO 1: Ejecutando agentes directamente...")
            
            employee_data = orchestration_request.get("employee_data", {})
            contract_data = orchestration_request.get("contract_data", {})
            documents = orchestration_request.get("documents", [])
            
            agent_results = {}
            successful_agents = 0
            
            # ‚úÖ EJECUTAR AGENTES UNO POR UNO DIRECTAMENTE
            try:
                # Initial Data Collection
                if self.agents[AgentType.INITIAL_DATA_COLLECTION.value]:
                    initial_result = self.agents[AgentType.INITIAL_DATA_COLLECTION.value].process_request({
                        "employee_id": employee_id,
                        "session_id": session_id,
                        "employee_data": employee_data
                    })
                    
                    agent_results["initial_data_collection_agent"] = initial_result or {}
                    if initial_result and initial_result.get("success", False):
                        successful_agents += 1
                    logger.info("‚úÖ Initial Data Collection ejecutado")
            except Exception as e:
                logger.error(f"‚ùå Initial Data Collection error: {e}")
                agent_results["initial_data_collection_agent"] = {"success": False, "error": str(e)}

            try:
                # Confirmation Data
                if self.agents[AgentType.CONFIRMATION_DATA.value]:
                    confirmation_result = self.agents[AgentType.CONFIRMATION_DATA.value].process_request({
                        "employee_id": employee_id,
                        "session_id": session_id,
                        "contract_data": contract_data,
                        "employee_context": employee_data
                    })
                    
                    agent_results["confirmation_data_agent"] = confirmation_result or {}
                    if confirmation_result and confirmation_result.get("success", False):
                        successful_agents += 1
                    logger.info("‚úÖ Confirmation Data ejecutado")
            except Exception as e:
                logger.error(f"‚ùå Confirmation Data error: {e}")
                agent_results["confirmation_data_agent"] = {"success": False, "error": str(e)}

            try:
                # Documentation
                if self.agents[AgentType.DOCUMENTATION.value]:
                    doc_result = self.agents[AgentType.DOCUMENTATION.value].process_request({
                        "employee_id": employee_id,
                        "session_id": session_id,
                        "documents": documents,
                        "employee_context": employee_data
                    })
                    
                    agent_results["documentation_agent"] = doc_result or {}
                    if doc_result and doc_result.get("success", False):
                        successful_agents += 1
                    logger.info("‚úÖ Documentation ejecutado")
            except Exception as e:
                logger.error(f"‚ùå Documentation error: {e}")
                agent_results["documentation_agent"] = {"success": False, "error": str(e)}
            
            # ‚úÖ PASO 2: CALCULAR QUALITY SCORE DIRECTAMENTE
            logger.info(f"üîÑ PASO 2: Calculando quality score - {successful_agents} agentes exitosos")
            
            quality_score = 0.0
            
            # Calcular basado en agentes exitosos
            for agent_key, agent_result in agent_results.items():
                if isinstance(agent_result, dict):
                    if agent_result.get("success", False):
                        quality_score += 30.0  # 30% por agente exitoso
                        
                    # Bonus por scores espec√≠ficos
                    if "validation_score" in agent_result:
                        quality_score += min(agent_result["validation_score"] * 0.3, 10.0)
                    if "compliance_score" in agent_result:
                        quality_score += min(agent_result["compliance_score"] * 0.2, 10.0)
            
            # Limitar a 100%
            quality_score = min(quality_score, 100.0)
            
            logger.info(f"üìä QUALITY SCORE CALCULADO DIRECTAMENTE: {quality_score:.1f}%")
            
            # ‚úÖ PASO 3: CREAR DATOS CONSOLIDADOS B√ÅSICOS
            consolidated_employee_data = {"employee_id": employee_id}
            
            for agent_result in agent_results.values():
                if isinstance(agent_result, dict):
                    # Extraer datos de structured_data, contractual_data, etc.
                    for field in ["structured_data", "contractual_data", "agent_output"]:
                        if field in agent_result and isinstance(agent_result[field], dict):
                            if field == "structured_data":
                                employee_info = agent_result[field].get("employee_info", {})
                                consolidated_employee_data.update(employee_info)
                            else:
                                consolidated_employee_data.update(agent_result[field])
            
            # ‚úÖ RESULTADO FINAL DIRECTO
            result = {
                "success": quality_score >= 30.0,
                "orchestration_id": f"orch_direct_{utc_now().strftime('%Y%m%d_%H%M%S')}",
                "session_id": session_id,
                "employee_id": employee_id,
                "agent_results": agent_results,
                "consolidated_data": {
                    "aggregated_employee_data": consolidated_employee_data,
                    "data_quality_metrics": {
                        "overall_quality": quality_score,
                        "successful_agents": successful_agents,
                        "total_agents": 3,
                        "direct_calculation": True
                    }
                },
                "aggregation_result": {
                    "success": quality_score >= 30.0,
                    "overall_quality_score": quality_score,
                    "ready_for_sequential_pipeline": quality_score >= 40.0,
                    "direct_mode": True
                },
                "data_quality_score": quality_score,
                "ready_for_sequential_execution": quality_score >= 40.0,
                "sequential_pipeline_request": {
                    "employee_id": employee_id,
                    "session_id": session_id,
                    "consolidated_data": {"aggregated_employee_data": consolidated_employee_data},
                    "data_quality_score": quality_score
                } if quality_score >= 40.0 else {},
                "errors": [],
                "completion_status": "completed",
                "bypass_mode": True,
                "agent_execution_summary": {
                    "successful_agents": successful_agents,
                    "total_agents": 3,
                    "quality_score": quality_score,
                    "ready_for_pipeline": quality_score >= 40.0
                }
            }
            
            logger.info(f"‚úÖ WORKFLOW DIRECTO COMPLETADO:")
            logger.info(f"   - Success: {result['success']}")
            logger.info(f"   - Quality Score: {quality_score:.1f}%")
            logger.info(f"   - Agentes exitosos: {successful_agents}/3")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error cr√≠tico en workflow directo: {e}")
            return {
                "success": False,
                "agent_results": {},
                "orchestration_id": "error_fallback",
                "employee_id": orchestration_request.get("employee_id", "fallback"),
                "session_id": "error_session",
                "data_quality_score": 0.0,
                "errors": [str(e)],
                "completion_status": "error"
            }

class SequentialPipelineWorkflow:
    """Sequential Pipeline CON ERROR HANDLING"""

    def __init__(self):
        self.graph = None
        self.agents = {
            AgentType.IT_PROVISIONING.value: None,
            AgentType.CONTRACT_MANAGEMENT.value: None,
            AgentType.MEETING_COORDINATION.value: None
        }
        self.progress_tracker = None
        self._setup_agents()
        self._build_graph()

    def _setup_agents(self):
        """Inicializar agentes del pipeline secuencial"""
        try:
            self.agents[AgentType.IT_PROVISIONING.value] = ITProvisioningAgent()
            self.agents[AgentType.CONTRACT_MANAGEMENT.value] = ContractManagementAgent()
            self.agents[AgentType.MEETING_COORDINATION.value] = MeetingCoordinationAgent()
            self.progress_tracker = ProgressTrackerAgent()
            logger.info("‚úÖ Agentes SEQUENTIAL PIPELINE inicializados")
        except Exception as e:
            logger.error(f"‚ùå Error inicializando agentes pipeline: {e}")
            raise

    def _build_graph(self):
        """Grafo SIMPLE con Error Handling"""
        try:
            workflow = StateGraph(WorkflowState)
            
            workflow.add_node("initialize", self._initialize_pipeline)
            workflow.add_node("validate_input", self._validate_input_simple)
            workflow.add_node("execute_sequential_real", self._execute_sequential_real)
            workflow.add_node("validate_pipeline_quality", self._validate_pipeline_quality)
            workflow.add_node("finalize", self._finalize_pipeline_simple)
            workflow.add_node("handle_pipeline_errors", self._handle_pipeline_errors)

            workflow.set_entry_point("initialize")
            workflow.add_edge("initialize", "validate_input")
            
            workflow.add_conditional_edges(
                "validate_input",
                self._should_proceed_pipeline,
                {"proceed": "execute_sequential_real", "error": "handle_pipeline_errors"}
            )
            
            workflow.add_edge("execute_sequential_real", "validate_pipeline_quality")
            
            workflow.add_conditional_edges(
                "validate_pipeline_quality",
                self._should_finalize_or_handle_errors,
                {"finalize": "finalize", "handle_errors": "handle_pipeline_errors"}
            )
            
            workflow.add_edge("finalize", END)
            workflow.add_edge("handle_pipeline_errors", END)

            self.graph = workflow.compile()
            logger.info("‚úÖ Sequential Pipeline CON ERROR HANDLING construido")
        except Exception as e:
            logger.error(f"‚ùå Error construyendo pipeline: {e}")
            raise

    async def _initialize_pipeline(self, state: WorkflowState) -> WorkflowState:
        """Inicializar pipeline"""
        try:
            state["current_phase"] = "sequential_initiated"
            state["progress_percentage"] = 0.0
            state["pipeline_results"] = {}
            state["errors"] = []
            
            # Error Handling initialization
            state["error_handling_active"] = False
            state["quality_score_issues"] = []
            state["agent_failure_count"] = 0
            
            logger.info("‚úÖ Sequential Pipeline inicializado")
            return state
        except Exception as e:
            state["errors"] = [str(e)]
            return state

    async def _validate_input_simple(self, state: WorkflowState) -> WorkflowState:
        """Validar input del pipeline"""
        try:
            consolidated_data = state.get("consolidated_data", {})
            
            # ‚úÖ VALIDACI√ìN REAL
            has_employee_data = bool(consolidated_data.get("aggregated_employee_data", {}))
            input_quality_score = state.get("data_quality_score", 0.0)
            
            if has_employee_data and input_quality_score >= 30.0:
                state["pipeline_input_data"] = {"ready": True, "validated": True}
                logger.info(f"‚úÖ Pipeline input v√°lido: quality={input_quality_score:.1f}%")
            else:
                state["pipeline_input_data"] = {"ready": False, "validation_failed": True}
                state["quality_score_issues"].append("insufficient_input_quality")
                logger.warning(f"‚ö†Ô∏è Pipeline input insuficiente: quality={input_quality_score:.1f}%")
            
            return state
        except Exception as e:
            state["pipeline_input_data"] = {"ready": False, "error": str(e)}
            return state

    def _should_proceed_pipeline(self, state: WorkflowState) -> str:
        """Decidir si proceder con pipeline"""
        input_ready = state.get("pipeline_input_data", {}).get("ready", False)
        return "proceed" if input_ready else "error"

    async def _execute_sequential_real(self, state: WorkflowState) -> WorkflowState:
        """Ejecutar agentes secuencialmente CON DATOS REALES"""
        try:
            logger.info("üîÑ Ejecutando Sequential Pipeline CON DATOS REALES")
            
            consolidated_data = state.get("consolidated_data", {})
            employee_data = consolidated_data.get("aggregated_employee_data", {})
            session_id = state.get("session_id")
            
            results = {}
            successful_stages = 0
            failed_stages = 0

            # ‚úÖ IT PROVISIONING REAL
            try:
                if self.agents[AgentType.IT_PROVISIONING.value]:
                    logger.info("üîÑ Ejecutando IT Provisioning REAL...")
                    
                    it_request = {
                        "employee_id": state["employee_id"],
                        "session_id": session_id,
                        "employee_data": employee_data,
                        "consolidated_data": consolidated_data
                    }
                    
                    it_result = self.agents[AgentType.IT_PROVISIONING.value].process_request(it_request)
                    
                    if it_result and it_result.get("success", False):
                        results["it_provisioning"] = {
                            **it_result,
                            "agent_id": "it_provisioning_agent",
                            "data_source": "real_pipeline_data"
                        }
                        successful_stages += 1
                        logger.info("‚úÖ IT Provisioning REAL exitoso")
                    else:
                        results["it_provisioning"] = {
                            "success": False,
                            "agent_id": "it_provisioning_agent",
                            "error": it_result.get("error", "IT Provisioning failed"),
                            "data_source": "real_pipeline_data"
                        }
                        failed_stages += 1
                        logger.warning("‚ö†Ô∏è IT Provisioning REAL fall√≥")
                        
            except Exception as e:
                logger.error(f"‚ùå IT Provisioning error: {e}")
                results["it_provisioning"] = {
                    "success": False,
                    "agent_id": "it_provisioning_agent",
                    "error": str(e)
                }
                failed_stages += 1

            # ‚úÖ CONTRACT MANAGEMENT REAL
            try:
                if self.agents[AgentType.CONTRACT_MANAGEMENT.value]:
                    logger.info("üîÑ Ejecutando Contract Management REAL...")
                    
                    contract_request = {
                        "employee_id": state["employee_id"],
                        "session_id": session_id,
                        "employee_data": employee_data,
                        "it_provisioning_result": results.get("it_provisioning", {}),
                        "consolidated_data": consolidated_data
                    }
                    
                    contract_result = self.agents[AgentType.CONTRACT_MANAGEMENT.value].process_request(contract_request)
                    
                    if contract_result and contract_result.get("success", False):
                        results["contract_management"] = {
                            **contract_result,
                            "agent_id": "contract_management_agent",
                            "data_source": "real_pipeline_data"
                        }
                        successful_stages += 1
                        logger.info("‚úÖ Contract Management REAL exitoso")
                    else:
                        results["contract_management"] = {
                            "success": False,
                            "agent_id": "contract_management_agent",
                            "error": contract_result.get("error", "Contract Management failed"),
                            "data_source": "real_pipeline_data"
                        }
                        failed_stages += 1
                        logger.warning("‚ö†Ô∏è Contract Management REAL fall√≥")
                        
            except Exception as e:
                logger.error(f"‚ùå Contract Management error: {e}")
                results["contract_management"] = {
                    "success": False,
                    "agent_id": "contract_management_agent",
                    "error": str(e)
                }
                failed_stages += 1

            # ‚úÖ MEETING COORDINATION REAL
            try:
                if self.agents[AgentType.MEETING_COORDINATION.value]:
                    logger.info("üîÑ Ejecutando Meeting Coordination REAL...")
                    
                    meeting_request = {
                        "employee_id": state["employee_id"],
                        "session_id": session_id,
                        "employee_data": employee_data,
                        "it_result": results.get("it_provisioning", {}),
                        "contract_result": results.get("contract_management", {}),
                        "consolidated_data": consolidated_data
                    }
                    
                    meeting_result = self.agents[AgentType.MEETING_COORDINATION.value].process_request(meeting_request)
                    
                    if meeting_result and meeting_result.get("success", False):
                        results["meeting_coordination"] = {
                            **meeting_result,
                            "agent_id": "meeting_coordination_agent",
                            "data_source": "real_pipeline_data"
                        }
                        successful_stages += 1
                        logger.info("‚úÖ Meeting Coordination REAL exitoso")
                    else:
                        results["meeting_coordination"] = {
                            "success": False,
                            "agent_id": "meeting_coordination_agent",
                            "error": meeting_result.get("error", "Meeting Coordination failed"),
                            "data_source": "real_pipeline_data"
                        }
                        failed_stages += 1
                        logger.warning("‚ö†Ô∏è Meeting Coordination REAL fall√≥")
                        
            except Exception as e:
                logger.error(f"‚ùå Meeting Coordination error: {e}")
                results["meeting_coordination"] = {
                    "success": False,
                    "agent_id": "meeting_coordination_agent",
                    "error": str(e)
                }
                failed_stages += 1

            # ‚úÖ PROGRESS TRACKER REAL (Simple update)
            if self.progress_tracker:
                try:
                    progress_update = {
                        "employee_id": state["employee_id"],
                        "stages_completed": successful_stages,
                        "total_stages": 3,
                        "current_status": "pipeline_executing"
                    }
                    self.progress_tracker.process_request(progress_update)
                    logger.info("‚úÖ Progress Tracker actualizado")
                except Exception as e:
                    logger.warning(f"Progress Tracker fall√≥: {e}")

            # ‚úÖ CONSOLIDAR RESULTADOS REALES
            state["pipeline_results"] = results
            state["successful_stages"] = successful_stages
            state["failed_stages"] = failed_stages
            state["agent_failure_count"] = failed_stages
            state["progress_percentage"] = 90.0
            
            # ‚úÖ DETECTAR ISSUES PARA ERROR HANDLING
            if failed_stages >= 2:
                state["quality_score_issues"].append("multiple_pipeline_failures")
                
            overall_pipeline_quality = (successful_stages / 3.0) * 100.0
            state["pipeline_quality_score"] = overall_pipeline_quality
            
            if overall_pipeline_quality < 50.0:
                state["quality_score_issues"].append("low_pipeline_quality")
            
            logger.info(f"üìä Sequential Pipeline REAL completado:")
            logger.info(f"   - Exitosos: {successful_stages}/3")
            logger.info(f"   - Fallidos: {failed_stages}/3")
            logger.info(f"   - Quality: {overall_pipeline_quality:.1f}%")
            
            return state

        except Exception as e:
            logger.error(f"‚ùå Error cr√≠tico en sequential real: {e}")
            state["pipeline_results"] = {}
            state["successful_stages"] = 0
            state["failed_stages"] = 3
            state["agent_failure_count"] = 3
            state["quality_score_issues"].append("sequential_system_failure")
            return state

    async def _validate_pipeline_quality(self, state: WorkflowState) -> WorkflowState:
        """Validar calidad del pipeline"""
        try:
            successful_stages = state.get("successful_stages", 0)
            failed_stages = state.get("failed_stages", 0)
            quality_issues = state.get("quality_score_issues", [])
            pipeline_quality = state.get("pipeline_quality_score", 0.0)
            
            logger.info(f"üìä Validando calidad pipeline:")
            logger.info(f"   - Successful: {successful_stages}/3")
            logger.info(f"   - Failed: {failed_stages}/3")
            logger.info(f"   - Quality: {pipeline_quality:.1f}%")
            
            # ‚úÖ DETERMINAR SI NECESITA ERROR HANDLING
            needs_error_handling = [
                failed_stages >= 2,           # Multiple failures
                successful_stages == 0,       # Complete failure
                pipeline_quality < 30.0,      # Quality too low
                len(quality_issues) >= 2      # Multiple issues
            ]
            
            if any(needs_error_handling):
                state["next_pipeline_phase"] = "handle_errors"
                state["error_handling_active"] = True
                logger.warning("üö® Pipeline requiere Error Handling")
            else:
                state["next_pipeline_phase"] = "finalize"
                logger.info("‚úÖ Pipeline quality acceptable")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Error validando pipeline quality: {e}")
            state["next_pipeline_phase"] = "handle_errors"
            state["error_handling_active"] = True
            return state

    def _should_finalize_or_handle_errors(self, state: WorkflowState) -> str:
        """Decidir si finalizar o manejar errores"""
        next_phase = state.get("next_pipeline_phase", "finalize")
        logger.info(f"üîÑ Pipeline routing: {next_phase}")
        return next_phase

    async def _finalize_pipeline_simple(self, state: WorkflowState) -> WorkflowState:
        """Finalizar pipeline CON RESULTADOS REALES"""
        try:
            pipeline_results = state.get("pipeline_results", {})
            successful_stages = state.get("successful_stages", 0)
            pipeline_quality = state.get("pipeline_quality_score", 0.0)
            
            # ‚úÖ SUCCESS BASADO EN RESULTADOS REALES
            pipeline_success = successful_stages >= 2 and pipeline_quality >= 50.0
            
            state["pipeline_completed"] = True
            state["stages_completed"] = successful_stages
            state["employee_ready"] = pipeline_success
            state["progress_percentage"] = 100.0
            
            logger.info(f"‚úÖ Pipeline finalizado REAL:")
            logger.info(f"   - Success: {pipeline_success}")
            logger.info(f"   - Stages: {successful_stages}/3")
            logger.info(f"   - Quality: {pipeline_quality:.1f}%")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Error finalizando pipeline: {e}")
            state["pipeline_completed"] = False
            state["stages_completed"] = 0
            state["employee_ready"] = False
            return state

    async def _handle_pipeline_errors(self, state: WorkflowState) -> WorkflowState:
        """Manejar errores del pipeline - PREPARAR PARA ERROR HANDLING"""
        try:
            pipeline_results = state.get("pipeline_results", {})
            successful_stages = state.get("successful_stages", 0)
            failed_stages = state.get("failed_stages", 0)
            quality_issues = state.get("quality_score_issues", [])
            
            # ‚úÖ CONSOLIDAR ERROR INFO PARA ORCHESTRATOR ERROR HANDLING
            error_summary = {
                "pipeline_stage": "sequential_processing",
                "successful_stages": successful_stages,
                "failed_stages": failed_stages,
                "total_stages": 3,
                "quality_issues": quality_issues,
                "failed_agents": [k for k, v in pipeline_results.items() if not v.get("success", False)],
                "pipeline_quality_score": state.get("pipeline_quality_score", 0.0)
            }
            
            state["pipeline_completed"] = False
            state["stages_completed"] = successful_stages
            state["employee_ready"] = False
            state["pipeline_error_summary"] = error_summary
            state["requires_error_handling"] = True  # ‚úÖ SE√ëAL PARA ORCHESTRATOR
            
            logger.warning(f"üö® Pipeline ERROR HANDLING preparado:")
            logger.warning(f"   - Failed stages: {failed_stages}/3")
            logger.warning(f"   - Quality issues: {len(quality_issues)}")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Error en pipeline error handling: {e}")
            state["pipeline_completed"] = False
            state["requires_error_handling"] = True
            return state

    async def execute_sequential_pipeline(self, pipeline_request: SequentialPipelineRequest) -> Dict[str, Any]:
        """Ejecutar Sequential Pipeline CON DATOS REALES"""
        try:
            logger.info(f"üöÄ SEQUENTIAL PIPELINE REAL: {pipeline_request.employee_id}")
            
            # ‚úÖ ESTADO INICIAL CON DATOS REALES
            initial_state = {
                "orchestration_id": pipeline_request.orchestration_id,
                "employee_id": pipeline_request.employee_id,
                "session_id": pipeline_request.session_id,
                "consolidated_data": pipeline_request.consolidated_data,
                "data_quality_score": pipeline_request.data_quality_score,
                
                "current_phase": "sequential_initiated",
                "progress_percentage": 0.0,
                "messages": [HumanMessage(content=f"Iniciar Sequential Pipeline REAL para {pipeline_request.employee_id}")],
                "errors": [],
                "pipeline_input_data": {},
                "pipeline_results": {},
                
                # Error Handling
                "error_handling_active": False,
                "error_handling_results": {},
                "quality_score_issues": [],
                "agent_failure_count": 0
            }

            # ‚úÖ EJECUTAR PIPELINE
            config = {"recursion_limit": 50}
            final_state = await self.graph.ainvoke(initial_state, config=config)
            
            # ‚úÖ EXTRAER RESULTADOS REALES
            pipeline_results = final_state.get("pipeline_results", {})
            successful_stages = final_state.get("stages_completed", 0)
            pipeline_success = final_state.get("employee_ready", False)
            pipeline_quality = final_state.get("pipeline_quality_score", 0.0)
            
            # ‚úÖ CONSTRUIR RESULTADO REAL
            result_dict = {
                "success": pipeline_success,  # ‚úÖ REAL SUCCESS
                "employee_id": pipeline_request.employee_id,
                "session_id": pipeline_request.session_id,
                "orchestration_id": pipeline_request.orchestration_id,
                "employee_ready_for_onboarding": pipeline_success,
                "stages_completed": successful_stages,
                "stages_total": 3,
                "overall_quality_score": pipeline_quality,  # ‚úÖ REAL QUALITY
                "pipeline_results": pipeline_results,
                
                # Extract real onboarding timeline
                "onboarding_timeline": pipeline_results.get("meeting_coordination", {}).get("onboarding_timeline", {}),
                "stakeholders_engaged": pipeline_results.get("meeting_coordination", {}).get("identified_stakeholders", []),
                
                "errors": final_state.get("errors", []),
                "warnings": [],
                "next_actions": [
                    "Iniciar ejecuci√≥n de onboarding timeline",
                    "Monitorear asistencia a reuniones cr√≠ticas"
                ] if pipeline_success else [
                    "Revisar fases fallidas del pipeline",
                    "Activar Error Handling para resoluci√≥n"
                ],
                "requires_followup": not pipeline_success,
                
                # ‚úÖ ERROR HANDLING INFO REAL
                "requires_error_handling": final_state.get("requires_error_handling", False),
                "quality_issues_detected": final_state.get("quality_score_issues", []),
                "pipeline_error_summary": final_state.get("pipeline_error_summary", {}),
                
                "processing_summary": {
                    "pipeline_completed": final_state.get("pipeline_completed", False),
                    "stages_completed": successful_stages,
                    "error_count": len(final_state.get("errors", [])),
                    "it_provisioning_success": pipeline_results.get("it_provisioning", {}).get("success", False),
                    "contract_management_success": pipeline_results.get("contract_management", {}).get("success", False),
                    "meeting_coordination_success": pipeline_results.get("meeting_coordination", {}).get("success", False)
                }
            }

            logger.info(f"üìä SEQUENTIAL PIPELINE REAL completado:")
            logger.info(f"   - Success: {result_dict['success']}")
            logger.info(f"   - Quality: {pipeline_quality:.1f}%")
            logger.info(f"   - Requires Error Handling: {result_dict.get('requires_error_handling', False)}")
            
            return result_dict

        except Exception as e:
            logger.error(f"‚ùå Error cr√≠tico en Sequential Pipeline real: {e}")
            
            # ‚úÖ ERROR RESULT QUE ACTIVAR√Å ERROR HANDLING
            return {
                "success": False,
                "error": str(e),
                "employee_id": pipeline_request.employee_id,
                "session_id": pipeline_request.session_id,
                "orchestration_id": pipeline_request.orchestration_id,
                "employee_ready_for_onboarding": False,
                "stages_completed": 0,
                "stages_total": 3,
                "overall_quality_score": 0.0,  # ‚úÖ QUALITY BAJA PARA ERROR HANDLING
                "pipeline_results": {},
                "errors": [str(e)],
                "requires_error_handling": True,  # ‚úÖ ACTIVAR ERROR HANDLING
                "processing_summary": {
                    "pipeline_completed": False,
                    "error": str(e),
                    "critical_failure": True
                }
            }

# ============================================================================
# INSTANCIAS GLOBALES CON ERROR HANDLING
# ============================================================================
data_collection_workflow = DataCollectionWorkflow()
sequential_pipeline_workflow = SequentialPipelineWorkflow()

# ============================================================================
# FUNCIONES AUXILIARES CON ERROR HANDLING
# ============================================================================
async def execute_data_collection_orchestration(orchestration_request: Dict[str, Any]) -> Dict[str, Any]:
    """Funci√≥n principal para ejecutar orquestaci√≥n DATA COLLECTION CON DATOS REALES"""
    return await data_collection_workflow.execute_workflow(orchestration_request)

async def execute_sequential_pipeline_orchestration(pipeline_request: SequentialPipelineRequest) -> Dict[str, Any]:
    """Funci√≥n principal para ejecutar SEQUENTIAL PIPELINE CON DATOS REALES"""
    return await sequential_pipeline_workflow.execute_sequential_pipeline(pipeline_request)

def get_workflow_status() -> Dict[str, Any]:
    """Obtener estado de workflows con Error Handling"""
    return {
        "data_collection_workflow": {
            "available": data_collection_workflow.graph is not None,
            "agents_initialized": len([a for a in data_collection_workflow.agents.values() if a is not None]),
            "total_agents": len(data_collection_workflow.agents),
            "data_aggregator_available": data_collection_workflow.data_aggregator is not None,
            "error_handling_integrated": True
        },
        "sequential_pipeline_workflow": {
            "available": sequential_pipeline_workflow.graph is not None,
            "agents_initialized": len([a for a in sequential_pipeline_workflow.agents.values() if a is not None]),  
            "total_agents": len(sequential_pipeline_workflow.agents),
            "progress_tracker_available": sequential_pipeline_workflow.progress_tracker is not None,
            "error_handling_integrated": True
        },
        "total_workflow_nodes": (
            len(data_collection_workflow.graph.nodes) if data_collection_workflow.graph else 0
        ) + (
            len(sequential_pipeline_workflow.graph.nodes) if sequential_pipeline_workflow.graph else 0
        ),
        "error_handling_capabilities": {
            "real_data_processing": True,
            "quality_score_detection": True,
            "agent_failure_detection": True,
            "automatic_error_routing": True
        }
    }

async def test_workflow_connectivity() -> Dict[str, Any]:
    """Test de conectividad con Error Handling"""
    try:
        if data_collection_workflow.graph and sequential_pipeline_workflow.graph:
            return {
                "connectivity_test": "passed",
                "workflow_graph": "available",
                "data_collection_nodes": len(data_collection_workflow.graph.nodes),
                "sequential_pipeline_nodes": len(sequential_pipeline_workflow.graph.nodes),
                "agents_status": {
                    **{f"dc_{agent_type}": "initialized" if agent else "not_initialized"
                       for agent_type, agent in data_collection_workflow.agents.items()},
                    **{f"sp_{agent_type}": "initialized" if agent else "not_initialized"
                       for agent_type, agent in sequential_pipeline_workflow.agents.items()}
                },
                "error_handling_ready": True,
                "real_data_processing_enabled": True
            }
        else:
            return {
                "connectivity_test": "failed", 
                "error": "Workflow graphs not available",
                "error_handling_ready": False
            }
    except Exception as e:
        return {
            "connectivity_test": "failed", 
            "error": str(e),
            "error_handling_ready": False
        }