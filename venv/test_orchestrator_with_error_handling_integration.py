import asyncio
import sys
import os
from datetime import datetime
from loguru import logger

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from agents.orchestrator.agent import OrchestratorAgent
from agents.orchestrator.schemas import OrchestrationRequest, AgentType, OrchestrationPattern
from shared.models import Priority
from core.state_management.state_manager import state_manager

def create_valid_test_request():
    """Crear request V√ÅLIDO que deber√≠a funcionar correctamente"""
    return OrchestrationRequest(
        employee_id="EMP_ERROR_HANDLING_VALID_001",
        employee_data={
            "employee_id": "EMP_ERROR_HANDLING_VALID_001",
            "first_name": "Maria",
            "middle_name": "Isabel",
            "last_name": "Rodriguez", 
            "mothers_lastname": "Gonzalez",
            "id_card": "1-1234-5678",
            "passport": "CR987654321",
            "email": "maria.rodriguez@empresa.com",
            "phone": "+506-7777-8888",
            "position": "Senior Data Analyst",
            "department": "Analytics",
            "university": "Universidad de Costa Rica",
            "career": "Estad√≠stica"
        },
        contract_data={
            "salary": 85000,
            "currency": "USD",
            "employment_type": "full_time",
            "start_date": "2025-01-20",
            "contract_duration": "indefinite",
            "benefits_package": "complete"
        },
        documents=[
            {"type": "cv", "filename": "maria_rodriguez_cv.pdf"},
            {"type": "id_copy", "filename": "cedula_maria.pdf"},
            {"type": "diploma", "filename": "titulo_estadistica.pdf"},
            {"type": "references", "filename": "referencias_laborales.pdf"}
        ],
        orchestration_pattern=OrchestrationPattern.CONCURRENT_DATA_COLLECTION,
        priority=Priority.HIGH
    )

def create_error_inducing_request():
    """Crear request con ERRORES que debe activar Error Handling"""
    return OrchestrationRequest(
        employee_id="EMP_ERROR_HANDLING_FAIL_002",
        employee_data={
            # ‚ùå DATOS INCOMPLETOS/ERR√ìNEOS
            "employee_id": "EMP_ERROR_HANDLING_FAIL_002",
            "first_name": "",  # ‚ùå Nombre vac√≠o
            "last_name": "ErrorTest",
            "email": "invalid-email",  # ‚ùå Email inv√°lido
            "phone": "123",  # ‚ùå Tel√©fono inv√°lido
            "position": "",  # ‚ùå Posici√≥n vac√≠a
            "department": "",  # ‚ùå Departamento vac√≠o
            # ‚ùå Faltan campos cr√≠ticos: id_card, university, career, etc.
        },
        contract_data={
            # ‚ùå DATOS CONTRACTUALES ERR√ìNEOS
            "salary": -1000,  # ‚ùå Salario negativo
            "currency": "INVALID",  # ‚ùå Moneda inv√°lida
            "employment_type": "",  # ‚ùå Tipo vac√≠o
            "start_date": "invalid-date",  # ‚ùå Fecha inv√°lida
            # ‚ùå Faltan campos cr√≠ticos
        },
        documents=[
            # ‚ùå DOCUMENTOS INSUFICIENTES (solo 1, deber√≠an ser al menos 3)
            {"type": "invalid", "filename": ""}  # ‚ùå Documento inv√°lido
        ],
        orchestration_pattern=OrchestrationPattern.CONCURRENT_DATA_COLLECTION,
        priority=Priority.LOW  # ‚ùå Prioridad baja
    )

async def test_error_handling_agents_availability():
    """Test 1: Verificar que los agentes de Error Handling est√°n disponibles"""
    logger.info("=" * 80)
    logger.info("TEST 1: VERIFICAR DISPONIBILIDAD AGENTES ERROR HANDLING")
    logger.info("=" * 80)
    
    orchestrator = OrchestratorAgent()
    
    # Verificar que los agentes Error Handling est√°n inicializados
    assert hasattr(orchestrator, 'error_classification_agent'), "‚ùå Error Classification Agent no disponible"
    assert hasattr(orchestrator, 'recovery_agent'), "‚ùå Recovery Agent no disponible"
    assert hasattr(orchestrator, 'human_handoff_agent'), "‚ùå Human Handoff Agent no disponible"
    assert hasattr(orchestrator, 'audit_trail_agent'), "‚ùå Audit Trail Agent no disponible"
    
    # Test de integraci√≥n con Error Handling
    integration_result = await orchestrator.test_full_integration()
    
    assert integration_result["architecture_version"] == "3.0_with_error_handling"
    assert integration_result["error_handling_integrated"] == True
    
    error_handling_status = integration_result.get("error_handling_status", {})
    assert error_handling_status["error_classification_available"] == True
    assert error_handling_status["recovery_agent_available"] == True
    assert error_handling_status["human_handoff_available"] == True
    assert error_handling_status["audit_trail_available"] == True
    
    logger.info("‚úÖ Error Classification Agent: Disponible")
    logger.info("‚úÖ Recovery Agent: Disponible")
    logger.info("‚úÖ Human Handoff Agent: Disponible")
    logger.info("‚úÖ Audit Trail Agent: Disponible")
    logger.info(f"‚úÖ Arquitectura version: {integration_result['architecture_version']}")
    logger.info(f"‚úÖ Error Handling integrado: {integration_result['error_handling_integrated']}")
    
    return integration_result

async def test_valid_orchestration_no_error_handling():
    """Test 2: Orquestaci√≥n v√°lida que NO debe activar Error Handling"""
    logger.info("=" * 80)
    logger.info("TEST 2: ORQUESTACI√ìN V√ÅLIDA - NO ERROR HANDLING")
    logger.info("=" * 80)
    
    orchestrator = OrchestratorAgent()
    valid_request = create_valid_test_request()
    
    logger.info(f"üîÑ Procesando empleado v√°lido: {valid_request.employee_id}")
    
    # Ejecutar orquestaci√≥n completa
    result = await orchestrator.execute_complete_onboarding_orchestration(valid_request)
    
    # Verificaciones b√°sicas
    assert result["success"] == True, f"‚ùå Orquestaci√≥n v√°lida fall√≥: {result.get('errors', [])}"
    assert result["session_id"] is not None, "‚ùå Session ID no generado"
    
    # ‚úÖ VERIFICAR QUE ERROR HANDLING NO SE ACTIV√ì
    error_handling_executed = result.get("error_handling_executed", False)
    assert error_handling_executed == False, "‚ùå Error Handling se activ√≥ innecesariamente"
    
    # Verificar calidad de datos
    data_quality_score = result.get("data_quality_score", 0.0)
    assert data_quality_score >= 30.0, f"‚ùå Quality score muy bajo: {data_quality_score:.1f}%"
    
    # Verificar sequential pipeline
    sequential_executed = result.get("sequential_pipeline_executed", False)
    employee_ready = result.get("employee_ready_for_onboarding", False)
    
    logger.info(f"‚úÖ Orquestaci√≥n exitosa: {result['success']}")
    logger.info(f"‚úÖ Quality Score: {data_quality_score:.1f}%")
    logger.info(f"‚úÖ Error Handling NO ejecutado: {not error_handling_executed}")
    logger.info(f"‚úÖ Sequential Pipeline: {sequential_executed}")
    logger.info(f"‚úÖ Empleado listo: {employee_ready}")
    
    return result

async def test_invalid_orchestration_triggers_error_handling():
    """Test 3: Orquestaci√≥n inv√°lida que DEBE activar Error Handling"""
    logger.info("=" * 80)
    logger.info("TEST 3: ORQUESTACI√ìN INV√ÅLIDA - DEBE ACTIVAR ERROR HANDLING")
    logger.info("=" * 80)
    
    orchestrator = OrchestratorAgent()
    invalid_request = create_error_inducing_request()
    
    logger.info(f"üîÑ Procesando empleado con errores: {invalid_request.employee_id}")
    logger.info("üîç Datos err√≥neos incluyen:")
    logger.info("   - Nombre vac√≠o")
    logger.info("   - Email inv√°lido") 
    logger.info("   - Salario negativo")
    logger.info("   - Documentos insuficientes")
    
    start_time = datetime.now()
    
    # Ejecutar orquestaci√≥n que deber√≠a fallar
    result = await orchestrator.execute_complete_onboarding_orchestration(invalid_request)
    
    end_time = datetime.now()
    processing_time = (end_time - start_time).total_seconds()
    
    # ‚úÖ VERIFICAR QUE ERROR HANDLING SE ACTIV√ì
    error_handling_executed = result.get("error_handling_executed", False)
    assert error_handling_executed == True, "‚ùå ERROR HANDLING NO SE ACTIV√ì con datos err√≥neos"
    
    # Verificar resultado de Error Handling
    error_handling_result = result.get("error_handling_result", {})
    assert error_handling_result is not None, "‚ùå No hay resultado de Error Handling"
    
    error_handling_success = error_handling_result.get("error_handling_success", False)
    
    # Verificar componentes de Error Handling
    classification_result = error_handling_result.get("classification_result", {})
    recovery_result = error_handling_result.get("recovery_result")
    handoff_result = error_handling_result.get("handoff_result") 
    audit_result = error_handling_result.get("audit_result", {})
    
    logger.info(f"‚úÖ ERROR HANDLING ACTIVADO: {error_handling_executed}")
    logger.info(f"‚úÖ Error Handling exitoso: {error_handling_success}")
    logger.info(f"‚úÖ Tiempo de procesamiento: {processing_time:.2f}s")
    
    # Verificar Error Classification
    if classification_result:
        logger.info(f"‚úÖ Error Classification ejecutado: {classification_result.get('success', False)}")
        logger.info(f"   - Estrategia: {classification_result.get('recovery_strategy', 'N/A')}")
        logger.info(f"   - Severidad: {classification_result.get('error_severity', 'N/A')}")
    
    # Verificar Recovery
    if recovery_result:
        logger.info(f"‚úÖ Recovery ejecutado: {recovery_result.get('success', False)}")
        logger.info(f"   - Status: {recovery_result.get('final_status', 'N/A')}")
    
    # Verificar Human Handoff
    if handoff_result:
        logger.info(f"‚úÖ Human Handoff ejecutado: {handoff_result.get('success', False)}")
        specialist = handoff_result.get('specialist_assignment', {})
        logger.info(f"   - Especialista: {specialist.get('name', 'N/A')}")
    
    # Verificar Audit Trail
    if audit_result:
        logger.info(f"‚úÖ Audit Trail ejecutado: {audit_result.get('success', False)}")
        audit_summary = audit_result.get('audit_summary', {})
        logger.info(f"   - Eventos auditados: {audit_summary.get('total_events_logged', 0)}")
    
    return result

async def test_quality_score_threshold_trigger():
    """Test 4: Verificar trigger por Quality Score bajo"""
    logger.info("=" * 80)
    logger.info("TEST 4: TRIGGER POR QUALITY SCORE BAJO")
    logger.info("=" * 80)
    
    orchestrator = OrchestratorAgent()
    
    # Request que deber√≠a generar quality score bajo
    low_quality_request = OrchestrationRequest(
        employee_id="EMP_LOW_QUALITY_003",
        employee_data={
            "employee_id": "EMP_LOW_QUALITY_003",
            "first_name": "Test",
            "last_name": "LowQuality",
            # ‚ùå Datos m√≠nimos - deber√≠a generar quality score bajo
        },
        contract_data={
            "salary": 50000
            # ‚ùå Datos contractuales m√≠nimos
        },
        documents=[],  # ‚ùå Sin documentos
        orchestration_pattern=OrchestrationPattern.CONCURRENT_DATA_COLLECTION,
        priority=Priority.MEDIUM
    )
    
    logger.info("üîÑ Procesando request con datos m√≠nimos para quality score bajo...")
    
    # Ejecutar solo Data Collection para verificar quality score
    data_collection_result = await orchestrator.orchestrate_onboarding_process(low_quality_request)
    
    data_quality_score = data_collection_result.get("data_quality_score", 100.0)
    
    logger.info(f"üìä Quality Score obtenido: {data_quality_score:.1f}%")
    
    # Verificar que el quality score est√° bajo
    if data_quality_score < 30.0:
        logger.info("‚úÖ Quality score < 30% - deber√≠a activar Error Handling")
        
        # Ejecutar orquestaci√≥n completa para ver Error Handling
        complete_result = await orchestrator.execute_complete_onboarding_orchestration(low_quality_request)
        
        error_handling_executed = complete_result.get("error_handling_executed", False)
        logger.info(f"‚úÖ Error Handling activado por quality score: {error_handling_executed}")
        
        return complete_result
    else:
        logger.warning(f"‚ö†Ô∏è Quality score {data_quality_score:.1f}% no es suficientemente bajo para trigger")
        return data_collection_result

async def test_error_handling_end_to_end_flow():
    """Test 5: Flujo completo End-to-End con Error Handling"""
    logger.info("=" * 80)
    logger.info("TEST 5: FLUJO COMPLETO END-TO-END CON ERROR HANDLING")
    logger.info("=" * 80)
    
    orchestrator = OrchestratorAgent()
    
    # Usar request con errores cr√≠ticos
    critical_error_request = create_error_inducing_request()
    critical_error_request.employee_id = "EMP_CRITICAL_E2E_004"
    
    logger.info(f"üöÄ INICIANDO FLUJO COMPLETO E2E: {critical_error_request.employee_id}")
    
    start_time = datetime.now()
    
    # Ejecutar flujo completo
    complete_result = await orchestrator.execute_complete_onboarding_orchestration(critical_error_request)
    
    end_time = datetime.now()
    total_time = (end_time - start_time).total_seconds()
    
    # Verificaciones del flujo completo
    session_id = complete_result.get("session_id")
    error_handling_executed = complete_result.get("error_handling_executed", False)
    
    logger.info(f"‚è±Ô∏è Tiempo total E2E: {total_time:.2f} segundos")
    logger.info(f"‚úÖ Session ID: {session_id}")
    logger.info(f"‚úÖ Error Handling ejecutado: {error_handling_executed}")
    
    # Verificar State Management
    if session_id:
        context = state_manager.get_employee_context(session_id)
        if context:
            logger.info(f"‚úÖ Contexto en State Management: {context.employee_id}")
            logger.info(f"‚úÖ Fase actual: {context.phase}")
        else:
            logger.warning("‚ö†Ô∏è No se encontr√≥ contexto en State Management")
    
    # Verificar resultado de Error Handling
    if error_handling_executed:
        error_handling_result = complete_result.get("error_handling_result", {})
        error_summary = error_handling_result.get("error_handling_summary", {})
        
        logger.info("üìã RESUMEN ERROR HANDLING:")
        logger.info(f"   - Classification: {error_summary.get('classification_executed', False)}")
        logger.info(f"   - Recovery: {error_summary.get('recovery_executed', False)}")
        logger.info(f"   - Handoff: {error_summary.get('handoff_executed', False)}")
        logger.info(f"   - Audit: {error_summary.get('audit_executed', False)}")
        
        final_resolution = error_handling_result.get("final_resolution", "unknown")
        logger.info(f"‚úÖ Resoluci√≥n final: {final_resolution}")
    
    # Calcular m√©tricas de √©xito
    success_indicators = [
        complete_result.get("success") is not None,  # Tiene resultado
        session_id is not None,  # Session ID generado
        error_handling_executed,  # Error Handling se activ√≥
        complete_result.get("architecture_version") == "3.0_with_error_handling"  # Versi√≥n correcta
    ]
    
    success_rate = (sum(success_indicators) / len(success_indicators)) * 100
    
    logger.info(f"üìä Success Rate E2E: {success_rate:.1f}%")
    
    return complete_result, {
        "success_rate": success_rate,
        "total_time": total_time,
        "error_handling_executed": error_handling_executed,
        "session_id": session_id
    }

async def run_error_handling_integration_tests():
    """Ejecutar todos los tests de integraci√≥n Error Handling"""
    logger.info("üöÄ INICIANDO TESTS DE INTEGRACI√ìN ERROR HANDLING")
    logger.info("=" * 100)
    
    test_results = {}
    
    try:
        # TEST 1: Disponibilidad de agentes
        logger.info("üìã Ejecutando Test 1: Disponibilidad agentes Error Handling...")
        test1_result = await test_error_handling_agents_availability()
        test_results["test1_availability"] = test1_result["error_handling_integrated"]
        
        # TEST 2: Orquestaci√≥n v√°lida (sin Error Handling)
        logger.info("üìã Ejecutando Test 2: Orquestaci√≥n v√°lida...")
        test2_result = await test_valid_orchestration_no_error_handling()
        test_results["test2_valid"] = test2_result["success"]
        
        # TEST 3: Orquestaci√≥n inv√°lida (con Error Handling)
        logger.info("üìã Ejecutando Test 3: Orquestaci√≥n inv√°lida...")
        test3_result = await test_invalid_orchestration_triggers_error_handling()
        test_results["test3_invalid"] = test3_result.get("error_handling_executed", False)
        
        # TEST 4: Quality Score trigger
        logger.info("üìã Ejecutando Test 4: Quality Score trigger...")
        test4_result = await test_quality_score_threshold_trigger()
        test_results["test4_quality"] = test4_result is not None
        
        # TEST 5: End-to-End completo
        logger.info("üìã Ejecutando Test 5: End-to-End completo...")
        test5_result, test5_metrics = await test_error_handling_end_to_end_flow()
        test_results["test5_e2e"] = test5_metrics["error_handling_executed"]
        
        # RESUMEN FINAL
        logger.info("=" * 100)
        logger.info("üéâ TODOS LOS TESTS DE ERROR HANDLING COMPLETADOS")
        logger.info("=" * 100)
        
        total_success_rate = (sum(test_results.values()) / len(test_results)) * 100
        
        logger.info("üìä RESULTADOS FINALES:")
        logger.info(f"   ‚úÖ Test 1 (Disponibilidad): {'PASS' if test_results['test1_availability'] else 'FAIL'}")
        logger.info(f"   ‚úÖ Test 2 (V√°lido): {'PASS' if test_results['test2_valid'] else 'FAIL'}")
        logger.info(f"   ‚úÖ Test 3 (Inv√°lido): {'PASS' if test_results['test3_invalid'] else 'FAIL'}")
        logger.info(f"   ‚úÖ Test 4 (Quality): {'PASS' if test_results['test4_quality'] else 'FAIL'}")
        logger.info(f"   ‚úÖ Test 5 (E2E): {'PASS' if test_results['test5_e2e'] else 'FAIL'}")
        logger.info(f"   üìà Success Rate Total: {total_success_rate:.1f}%")
        
        if total_success_rate >= 80:
            logger.info("üéØ ERROR HANDLING INTEGRACI√ìN: ‚úÖ EXITOSA")
            logger.info("üöÄ SISTEMA COMPLETO DE ONBOARDING CON ERROR HANDLING FUNCIONANDO")
        else:
            logger.warning("‚ö†Ô∏è ERROR HANDLING INTEGRACI√ìN: NECESITA AJUSTES")
            
        return True, test_results
        
    except Exception as e:
        logger.error("=" * 100)
        logger.error(f"‚ùå TESTS DE ERROR HANDLING FALLARON: {e}")
        logger.error("=" * 100)
        import traceback
        logger.error(traceback.format_exc())
        
        return False, {"error": str(e)}

if __name__ == "__main__":
    print("üöÄ INICIANDO TESTS DE INTEGRACI√ìN ERROR HANDLING CON ORCHESTRATOR")
    print("=" * 100)
    
    # Ejecutar tests
    success, results = asyncio.run(run_error_handling_integration_tests())
    
    # Resumen final
    print("\n" + "=" * 100)
    print("üìä RESUMEN FINAL - ERROR HANDLING INTEGRATION")
    print("=" * 100)
    
    if success:
        print("üéâ INTEGRACI√ìN ERROR HANDLING: ‚úÖ EXITOSA")
        print("üîß FUNCIONALIDADES VERIFICADAS:")
        print("   ‚úÖ Agentes Error Handling disponibles")
        print("   ‚úÖ Procesamiento de datos REALES")
        print("   ‚úÖ Detecci√≥n autom√°tica de errores") 
        print("   ‚úÖ Activaci√≥n de Error Handling")
        print("   ‚úÖ Flujo completo: Classification ‚Üí Recovery ‚Üí Handoff ‚Üí Audit")
        print("   ‚úÖ Integration con State Management")
        print("\nüöÄ SISTEMA DE ONBOARDING CON ERROR HANDLING COMPLETO Y FUNCIONAL")
    else:
        print("‚ùå INTEGRACI√ìN ERROR HANDLING: FALL√ì")
        print(f"üîß Error: {results.get('error', 'Unknown')}")
        print("\nüîß REQUIERE DEBUGGING Y CORRECCIONES")
    
    print("=" * 100)